{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "55b9bdfe-d66d-4f78-b4ea-cc5135c0dddc",
    "deletable": false
   },
   "source": [
    "## Homework 2 warm-up: *How to debug Jupyter notebooks*\n",
    "Before we start with Homework 2, let's experiment with a useful command to debug in Jupyter notebooks.\n",
    "\n",
    "When executing an operation in our Jupyter notebook, and we encounter an uncaught exception (as shown below), we can use [%debug](http://ipython.readthedocs.io/en/stable/interactive/magics.html#magic-debug) to enter into the stack frame where the exception occurred.\n",
    "\n",
    "Once we are inside the debugger, we can view local variables using `p variable_name`.  We can navigate between stack frames using `up` and `down`.  A full list of python debugger commands can be found [here](https://docs.python.org/3/library/pdb.html#debugger-commands).  When you are done with the debugger type `c` to continue running.\n",
    "\n",
    "Below, uncomment the `debug_me()` line, and then run the `%debug` statement below it.  Try entering some of the commands in the debugger session:\n",
    "```\n",
    "help\n",
    "p some_variable\n",
    "p b\n",
    "ll\n",
    "up\n",
    "c\n",
    "quit\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "e47256d0-43be-45a6-9bad-b66306ecf2f7",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def debug_me():\n",
    "    some_variable = 'hello world'\n",
    "    a = 1\n",
    "    b = 0\n",
    "    return a / b\n",
    "\n",
    "# debug_me()  # uncomment this line to try out the debugger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "d4ff314f-5ddd-430a-8482-fa294d7c844d",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "2aedd5fb-c443-4507-a2e4-93ad37f01954",
    "deletable": false
   },
   "source": [
    "# Homework 2 \u2014 Efficient Finite-State Methods\n",
    "\n",
    "Homework 2 focuses on using dynamic programming to compute expected rewards and optimal plans.  The methods explored here are fairly general.  Rather than write task-specific dynamic programming algorithms by hand, we will use *generic* algorithms that are built into the finite-state toolkit, and apply them to *task-specific* weighted finite-state machines.  Thus, our methods will apply broadly \u2014 whenever the models and reward functions can be defined using finite-state machines. \n",
    "\n",
    "**Chunking:** We are going to be doing a supervised *chunking* task.  \"Chunks\" are interesting non-empty substrings of the input $\\boldsymbol{x}$.  The correct chunks $\\boldsymbol{y}$ are known not to overlap with one another, and our prediction $\\boldsymbol{a}$ is similarly a set of non-overlapping chunks.  So chunking is sort of like parsing without any recursive structure.  There are $O(J^2)$ possible chunks in a sentence of length $J$, namely the substrings of the form $\\boldsymbol{x}_{i:j}$ for $0 \\leq i < j \\leq J$.  We would like our algorithms to run in $O(J^2)$ as well (rather than the $O(J^3)$ that is needed for the more general problem of context-free parsing).\n",
    "\n",
    "Specifically, we will consider the task of named entity recognition (NER), in which the chunks refer to \"named entities\" such as specific persons, places, and organizations.  Treating this as a chunking task means that our annotated data will not be able to mark both of the overlapping named entities in `[The [Johns Hopkins] University]`.  \n",
    "\n",
    "**Chunking as tagging:** We will encode a chunking as an \"IOB\" (or \"BIO\") tagging of the words in each sentence.  Thus, $\\boldsymbol{x} \\in {\\mathcal X}^*$ is a sequence of words, and $\\boldsymbol{y} \\in {\\mathcal Y}^* = \\{\\text{I,O,B}\\}^*$ is a sequence of tags.  The first word of every chunk is tagged with `B` (\"beginning\"), and the remaining words of that chunk are tagged with `I` (\"inside\").  All remaining words are tagged with `O` (\"outside\"). \n",
    "\n",
    "Given a sentence of length $J$, the set of legal taggings $\\boldsymbol{\\mathcal Y}$ is actually a bit smaller than ${\\mathcal Y}^\\text{J}$.  For example, it does not include `OII` or `III`, because that is not the correct encoding of any set of chunks, and hence could not be decoded.  The restriction is that every `I` must be immediately preceded by either `B` or another `I`.\n",
    "\n",
    "Note that these are unlabeled chunks.  If we wanted to label each chunk as `PERSON`, `ORGANIZATION`, etc., then we would need a larger tag set ${\\mathcal Y}$ to encode this labeled chunking.\n",
    "\n",
    "**Model:** As our tagging model $p(\\boldsymbol{y} \\mid \\boldsymbol{x})$, we'll use a first-order linear-chain CRF with features that are described below.  Just as for HMMs, inference in this simple model can be performed in $O(J)$ time by the forward-backward algorithm.  We'll discuss some $O(J^2)$ computations later.\n",
    "\n",
    "**Datasets and Algorithms:** We'll work on the Dutch NER data from the CONLL 2002 Shared Task, in which all words are lowercased (so capitalization features can't be used to help).  We have prepared two different datasets for you:\n",
    "\n",
    "* The first dataset consists of `train-small` and `dev-small`.  These contain only sentences of length 5 or less and can be used for brute-force training (as in homework 1), since you can enumerate the entire set $\\boldsymbol{\\mathcal{Y}}$ when computing the gradient ($|\\boldsymbol{\\mathcal{Y}}| < 3^5 = 243$).\n",
    "\n",
    "* The second dataset consists of `train`, `dev` and `test`, which contain much longer sequences (up to $45$ words) and thus can **not** be brute forced ($3^{45} = 2954312706550833698643$).  To deal with this larger domain, we will have to use the fact that our scoring function is decomposable, in the sense that we can score possible taggings $\\boldsymbol{y}$ and plans $\\boldsymbol{a}$ using FSTs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "c9952510-eed1-4863-a0a8-82b9bfeca47e",
    "deletable": false
   },
   "source": [
    "# Getting set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "a02750b7-42fb-4432-944e-2c2e02d907fc",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# the current problem size is not large enough to make good use of threads\n",
    "# set this before we import numpy\n",
    "import os\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "import numpy as np\n",
    "from scipy.misc import logsumexp\n",
    "import sys\n",
    "import re\n",
    "from itertools import islice, product\n",
    "from pprint import pprint\n",
    "import math\n",
    "import csv\n",
    "from collections import namedtuple   \n",
    "\n",
    "Data_type = namedtuple('Data', ['xx', 'oo', 'yy'])\n",
    "\n",
    "def iterate_data(filename='train', *, max_examples=None):\n",
    "    file = open(filename+'.tsv')\n",
    "    for n, row in enumerate(csv.DictReader(file, delimiter='\\t')):\n",
    "        if max_examples and n >= max_examples:\n",
    "            break\n",
    "        yield Data_type(\n",
    "            xx=tuple(row['xx'].split()),\n",
    "            oo=tuple(row['oo'].split()) if 'oo' in row else None,\n",
    "            yy=tuple(row['yy'].split()) if 'yy' in row else None,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "3c92920d-fd96-4a9b-9281-75aba784c2d1",
    "deletable": false
   },
   "source": [
    "We provided the classes `TaskSetting`, `ProbabilityModel`, `BoltzmannModel`, `DecisionAgent` from homework 1 in the file `seq2class_homework1.py`. (One change: `Probability.params` is now an ordinary attribute; we removed its property getter/setter.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "29954b93-5142-48a6-a7a8-6f07229fe530",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "from seq2class_homework1 import (\n",
    "    TaskSetting,\n",
    "    ProbabilityModel,\n",
    "    BoltzmannModel,\n",
    "    DecisionAgent,\n",
    "    ViterbiAgent,\n",
    "    BayesAgent,\n",
    "    L2LogLikelihood,\n",
    "    SGDTrainer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "0abe4c90-0f16-4868-b84a-9ae33aabc85d",
    "deletable": false
   },
   "source": [
    "Let's look at our data.  (Not the test data, of course!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "294675c1-d68b-476e-8e73-1ab38c7f15d5",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "print(next(iterate_data('train')))\n",
    "print(\"\\n\",next(iterate_data('dev')))\n",
    "print(\"\\n\",next(iterate_data('dev-small')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "b894aca1-a6d4-4bbf-b7c8-344b98c63b51",
    "deletable": false
   },
   "source": [
    "# Integerization\n",
    "\n",
    "In the previous homework, our input alphabet $\\mathcal X$ was fairly small, consisting of only lower and upper case letters.  In this assignment, we will define $\\mathcal X$ to consist of entire words instead of just letters.  \n",
    "\n",
    "It is sometimes helpful to associate each word type in the vocabulary with an unique integer \u2014 a technique called \"integerization.\"  This integer index can then be used to help look up counts or parameters associated with that word type.  This is sometimes more convenient then using the word type itself as a dictionary key, for example when dealing with libraries like numpy, PyTorch, and OpenFST that assume integer indices.\n",
    "\n",
    "Another use of integerization is to associate each parameter in the model with a unique integer.  For example, each $n$-gram feature might be named by an $n$-tuple of strings.  If the tuple's integer index is 7, the corresponding feature weight is stored at `theta[7]`, where `theta` is the parameter vector.\n",
    "\n",
    "Here's a class for representing vocabularies and parameters in this way.  If you are unfamiliar with the special `__` method names, check [this Python documentation](https://docs.python.org/3/reference/datamodel.html#special-method-names)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "4bbad834-e6ee-452b-9510-bb8daee1d850",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "class Integerizer(object):\n",
    "    \"\"\"\n",
    "    A collection of distinct object types, such as a vocabulary or a set of parameter names,\n",
    "    that are associated with consecutive ints starting at 0.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, iterable=[]):\n",
    "        \"\"\"\n",
    "        Initialize the collection to the empty set, or to the set of *unique* objects in its argument\n",
    "        (in order of first occurrence).\n",
    "        \"\"\"\n",
    "        # Set up a pair of data structures to convert objects to ints and back again.\n",
    "        self._objects = []   # list of all unique objects that have been added so far\n",
    "        self._indices = {}   # maps each object to its integer position in the list\n",
    "        # Add any objects that were given.\n",
    "        self.update(iterable)\n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Number of objects in the collection.\n",
    "        \"\"\"\n",
    "        return len(self._objects)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        \"\"\"\n",
    "        Iterate over all the objects in the collection.\n",
    "        \"\"\"\n",
    "        return iter(self._objects)\n",
    "    \n",
    "    def __contains__(self, obj):\n",
    "        \"\"\"\n",
    "        Does the collection contain this object?  (Implements `in`.)\n",
    "        \"\"\"\n",
    "        return self.index(obj) is not None\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Return the object with a given index.  \n",
    "        (Implements subscripting, e.g., `my_integerizer[3]`.)\n",
    "        \"\"\"\n",
    "        return self._objects[index]\n",
    "        \n",
    "    def index(self, obj, add=False):\n",
    "        \"\"\"\n",
    "        The integer associated with a given object, or `None` if the object is not in the collection (OOV).  \n",
    "        Use `add=True` to add the object if it is not present. \n",
    "        \"\"\"\n",
    "        try:\n",
    "            return self._indices[obj]\n",
    "        except KeyError:\n",
    "            if add:\n",
    "                # add the object to both data structures\n",
    "                i = len(self)\n",
    "                self._objects.append(obj)\n",
    "                self._indices[obj] = i\n",
    "                return i\n",
    "            else:\n",
    "                return None\n",
    "            \n",
    "    def add(self, obj):\n",
    "        \"\"\"\n",
    "        Add the object if it is not already in the collection.\n",
    "        Similar to `set.add` (or `list.append`).\n",
    "        \"\"\"\n",
    "        self.index(obj, add=True)  # call for side effect; ignore return value\n",
    "        \n",
    "    def update(self, iterable):\n",
    "        \"\"\"\n",
    "        Add all the objects if they are not already in the collection.\n",
    "        Similar to `set.update` (or `list.extend`).\n",
    "        \"\"\"\n",
    "        for obj in iterable:\n",
    "            self.add(obj) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "6112b1a1-ec69-40b9-b874-3622dfd731c6",
    "deletable": false
   },
   "source": [
    "Let's try it out.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "d0ec3f2f-e360-4a30-892b-459b554212d1",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "vocab = Integerizer(['','hello','goodbye'])   # 0 represents the empty string '' (epsilon), as in OpenFST\n",
    "(vocab[2], vocab.index('goodbye'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "fb6efc0a-952f-4ba2-bda7-d0ccf3c45555",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "sentence = ('hello','world','if','world','you','be')\n",
    "[vocab.index(w) for w in sentence]    # includes OOVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "b5bb30f7-c6bb-4b96-aa06-9d1a9497e7bb",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "[vocab.index(w, add=True) for w in sentence]   # expand vocabulary on demand, so no OOVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "6d3c649d-9264-4941-96d6-630526725e8a",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "278c6dda-1392-41f3-804c-4d5c32279417",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "'world' in vocab, 'mars' in vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "061c5322-88a1-4c30-8b4c-4553731e7c5a",
    "deletable": false
   },
   "source": [
    "# Parameter Dictionaries\n",
    "\n",
    "We wrote a `ParamDict` class that may be even more convenient.  Instead of mapping parameter names to integer indices, it maps them directly to the parameter values.  This can eliminate the need for `Integerizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "3264f1bb-9a85-4df9-bf96-94edd5216d65",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "from paramdict import ParamDict   # see paramdict.py for the details\n",
    "help(ParamDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "f9f5947a-d65e-4687-9571-8fda4915ca77",
    "deletable": false
   },
   "source": [
    "`ParamDict` is an extension of the built-in Python dictionary class (`dict`).  It can be initialized, queried, and modified in the same way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "374e31fe-b578-4f40-ab86-ddecf60b78de",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "params = ParamDict(Noun=2,Verb=3)\n",
    "params    # note that the default is given by the None entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "36acfa71-228c-499d-948b-f7dd6f631d7b",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "(params['Verb'],params['Noun','violin'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "9043660d-77ae-490f-b3c4-f699b4468a03",
    "deletable": false
   },
   "source": [
    "The main difference is that you can treat `ParamDict` objects as sparse vectors indexed by the parameter names, and do vector arithmetic on them.  Here's what a sparse gradient update to `params` looks like.  Notice that `gradient['Verb']` has the default value of 0, so the entry `params['Verb']` is not affected by the update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "66ca2e7c-5920-40c8-83c6-878e638603f5",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "gradient = ParamDict()\n",
    "gradient['Noun'],gradient['Noun','violin'] = 5,6\n",
    "params -= 0.01*gradient\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "368b2b07-5052-4043-bcf6-c94b419edcd1",
    "deletable": false
   },
   "source": [
    "*Note:* If you want to be extra-efficient, then you might not want your `ParamDict` keys to include full strings.  Instead, replace larger objects like the strings `'Noun'` and `'violin'` with small fixed-size objects like integers or pointers, which are compact to store and can be very rapidly hashed and compared.  To do this, when you read a string token, convert it to an integer using an `Integerizer`, or convert it to an [interned string](https://en.wikipedia.org/wiki/String_interning) using [`sys.intern`](https://docs.python.org/3/library/sys.html#sys.intern).  Then use tuples of these objects as the `ParamDict` keys for the various model features.  This efficiency trick might be worthwhile in an optimized Cython, C++, or Java implementation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "92f1f9cf-c4ce-4e57-9104-0c02d7882791",
    "deletable": false
   },
   "source": [
    "# Part 1: Setting up the task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "91c4c571-e80d-43c2-aa60-1e91194518cb",
    "deletable": false
   },
   "source": [
    "Let's construct `IobTask0`, a particular `TaskSetting` that will work for any chunking problem that is treated with IOB tagging.  All you need to write at this point is the `iterate_y` method (which will be called by `iterate_yy`). \n",
    "\n",
    "When defining this method, recall that $\\mathcal Y_x$ will contain sequences $\\boldsymbol{y}$ that are the same length as our input $\\boldsymbol{x}$ and that each word will be labeled with either `B` for the first word of a named entity, `I` for a later word of a named entity, or `O` for a word outside any named entity.  This implies that $\\boldsymbol{y}$ should never contain the bigram `OI`, nor should it start with `I`.\n",
    "\n",
    "You'll come back shortly to fill in the `reward` method as well.  So far, you are just following the framework we set up in Homework 1.  Later on in this notebook, we'll extend `IobTask0` to `IobTask`, a more efficient subclass that provides a finite-state description of the possible taggings, not just an iterator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "84e8939f-b635-4756-8643-54286d859a9d",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "class IobTask0(TaskSetting):\n",
    "\n",
    "    Y_alphabet = tuple('IOB')    # the output alphabet for this task\n",
    "    \n",
    "    def __init__(self, false_pos_penalty=1):\n",
    "        super().__init__()\n",
    "        self.false_pos_penalty = false_pos_penalty    # lambda\n",
    "        \n",
    "    def iterate_y(self, *, xx, oo=None, yy_prefix):\n",
    "        ### STUDENTS START\n",
    "        raise NotImplementedError()  # REPLACE ME\n",
    "        ### STUDENTS END\n",
    "        \n",
    "    # Could just use the inherited iterate_yy method, but let's extend it with assertions\n",
    "    # that the strings we're returning are actually legal.  (This might catch a bug, e.g.,\n",
    "    # you forgot to check whether a character observed in oo was legal given the prefix.)\n",
    "    def iterate_yy(self, xx, oo=None):\n",
    "        for yy in super().iterate_yy(xx=xx,oo=oo):\n",
    "            assert yy[0] != 'I'                # 'I' is illegal following BOS\n",
    "            assert 'OI' not in ''.join(yy)     # 'I' is illegal following 'O'\n",
    "            yield yy\n",
    "                \n",
    "    def reward(self, *, aa, xx, yy):\n",
    "        \"\"\"\n",
    "        The proxy reward of prediction aa on this sentence if the true chunking is yy.\n",
    "        \"\"\"\n",
    "        # Hint: call reward_F1_triple\n",
    "        ### STUDENTS START\n",
    "        raise NotImplementedError()  # REPLACE ME\n",
    "        ### STUDENTS END\n",
    "\n",
    "    def reward_F1_triple(self, *, aa, xx, yy):\n",
    "        \"\"\"\n",
    "        ***NEW***: returns a triple (true_pos, true, pos) used to compute corpus-level F1: \n",
    "           `true_pos` is the number of \"true positives\" (chunks reported by `aa` that are truly in `yy`) \n",
    "           `true` is the number of chunks that are truly in `yy`  \n",
    "           `pos` is the number of chunks reported by `aa`\n",
    "        \"\"\"\n",
    "        assert len(aa) == len(yy)\n",
    "        true = sum('B' == y for y in yy)\n",
    "        pos = sum('B' == a for a in aa)\n",
    "        true_pos = 0\n",
    "        I = False    # are we currently inside a true_pos chunk?\n",
    "        for i in range(len(aa)):\n",
    "            if I:\n",
    "                if aa[i] != 'I' or yy[i] != 'I':\n",
    "                    I = False       # aa and yy didn't both continue the chunk they were both in\n",
    "                    if aa[i] != 'I' and yy[i] != 'I':\n",
    "                        true_pos += 1   # aa and yy both ended the chunk they were both in, at same place i-1\n",
    "            if aa[i] == 'B' and yy[i] == 'B':\n",
    "                I = True    # both aa and yy started a new chunk at same place i\n",
    "        true_pos += I       # if I==True, then aa and yy both ended the chunk they were both in at end of string\n",
    "        return np.array([true, pos, true_pos])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "48aa369a-e86f-49e4-84a9-7dc0070eb77a",
    "deletable": false
   },
   "source": [
    "Now let's test that `iterate_yy` does the right thing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "a076e024-979f-45b1-a038-045aabbaa8c2",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "task0 = IobTask0()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "96e85113-9a45-41c9-a63f-de84f0abcc80",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "xx, oo, yy = next(iterate_data('dev-small'))\n",
    "print(xx,oo)\n",
    "yys = list(task0.iterate_yy(xx=xx,oo=oo))\n",
    "(len(yys), yys[:10])    # number of values and the first 10 of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "6813b5ce-51b4-4058-ac3c-4cbc053d2a14",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "oo=list(oo); oo[2]='I'   # change example slightly to observe one tag\n",
    "yys = list(task0.iterate_yy(xx=xx,oo=oo))\n",
    "(len(yys), yys[:10])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "caeeb45e-91df-4fa7-b1cc-9641ebebbc44",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# define your own tests here\n",
    "### STUDENTS START\n",
    "raise NotImplementedError()  # REPLACE ME\n",
    "### STUDENTS END\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "57c8df29-24f1-40af-a465-f28960002a97",
    "deletable": false
   },
   "source": [
    "## Rewards for the chunking task\n",
    "\n",
    "In the `IobTask` class above, we supplied two reward methods \u2014 not just the `reward` method that is required by `TaskSetting`, but another method called `reward_F1_triple`.  To see why, first let's review some definitions:\n",
    "* **True chunks:** `true` is the total number of chunks in the correct $\\boldsymbol{y}$ taggings for the test corpus.\n",
    "* **Positive findings:** `pos` is the total number of chunks in the predicted $\\boldsymbol{a}$ taggings for the test corpus.\n",
    "* **True positives:** `true_pos` is the total number of correctly predicted chunks, i.e., chunks that appear in both $\\boldsymbol{y}$ and $\\boldsymbol{a}$.  True positives are good!\n",
    "* **False positives:** `pos - true_pos` is the number of incorrectly predicted chunks.  False positives are bad (\"precision errors\").\n",
    "* **False negatives:** `true - true_pos` is the number of missed chunks.  False negatives are bad (\"recall errors\").\n",
    "* **True negatives:** This is not usually computed for a chunking task.  True negatives are all the *non*-chunks that we correctly avoid predicting as chunks; there are $O(J^2)$ of them.\n",
    "\n",
    "It is conventional to evaluate NER and other chunking tasks using the **corpus-level $F_1$ measure**.  Recall that $F_1$ is defined as the harmonic mean of precision and recall, $$F_1 = \\left( \\frac{\\text{precision}^{-1} + \\text{recall}^{-1}}{2} \\right)^{-1} = \\frac{2\\cdot\\text{true_pos}}{\\text{true}+\\text{pos}},$$\n",
    "where $$\\text{precision} = \\frac{\\text{true_pos}}{\\text{pos}}, \\text{recall} = \\frac{\\text{true_pos}}{\\text{true}}$$\n",
    "and here `true`, `pos`, and `true_pos` are the *total* counts from the *entire test corpus* (which are unlikely to be 0).  \n",
    "\n",
    "In the end, we will evaluate our decision agent on test data in this way, with the help of `reward_F1_triple`, which we have defined for you above.  It returns the `(true,pos,true_pos)` triple for the predicted `aa` given the true `yy`.  These triples can be summed over all sentences in the test corpus.  We have defined `IobTask.reward_F1_triple` for you, and here is a method to convert the summed triple to $F_1$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "3e4e7fe4-babb-4aa9-8ba6-4744cda3faae",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def F1(true, pos, true_pos):\n",
    "    \"\"\"\n",
    "    Compute an F1 score from the relevant count triple.\n",
    "    \"\"\"\n",
    "    if true+pos > 0:\n",
    "        f1 = 2*true_pos / (true+pos)\n",
    "    else: \n",
    "        f1 = 1   # full credit if there were no true chunks and we found none\n",
    "    precision = (true_pos / pos) if pos > 0 else math.nan  # precision of 0/0 is not well defined\n",
    "    recall = (true_pos / true) if true > 0 else 1          # recall for 0/0 is 1: full credit if there were no true chunks and we found none\n",
    "    print(f'F1 {f1}, precision: {precision}, recall: {recall}, true: {true}, pos: {pos}, true_pos: {true_pos}')\n",
    "    return f1   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "6bfb31b9-8d87-4927-b016-e7b168d5e909",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "triple = task0.reward_F1_triple(xx=None, \n",
    "                                   aa=('O','B','I','B','B','O','B','I','I'), \n",
    "                                   yy=('O','B','I','I','B','O','B','I','I'))\n",
    "triple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "894f64a9-0ae6-4699-b31f-18511d24031c",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "F1(*triple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "986f9c34-e06a-4ae3-88c6-307a323bf07e",
    "deletable": false
   },
   "source": [
    "But what decision agent should we use?  Unfortunately, it is somewhat tricky (though possible) to construct an efficient Bayes rule for the $F_1$ measure.  \n",
    "* First of all, the Bayes rule cannot just map each separate sentence to its best tagging.  The \"best\" tagging of one sentence actually depends on the other sentences!  So it would have to map the entire corpus to the best tagging of the corpus.  This would require annoying changes to our class design or our file formats.\n",
    "\n",
    "  Mathematically, the problem is that the $F_1$ formula is not simply a sum over sentences $i$.  (Rather, the sums are buried inside the definitions of `true`, `pos`, and `true_pos`.)  As a result, the expected corpus-level $F_1$ is not simply a sum over sentences, so we can't simply maximize it by maximizing the expected $F_1$ for each sentence separately.\n",
    "\n",
    "  Intuitively, the problem is that to improve the corpus-level $F_1$, it is more helpful to improve whichever is currently lower, precision or recall.  So in deciding what to do on sentence $\\boldsymbol{x}_i$, we need to know the precision and recall for other sentences.  If precision is low elsewhere, then we should be cautious and predict only the few chunks of $\\boldsymbol{x}_i$ where we are most confident, in order to get high precision even at the expense of recall.  If recall is low elsewhere, then we should be aggressive and predict lots of chunks, in order to get high recall even at the expense of precision.\n",
    "  \n",
    "  \n",
    "* Second, regardless of whether we want to maximize expected $F_1$ for a single sentence or for the whole test corpus, the Bayes rule prediction is tricky to compute efficiently, for similar reasons.  It can't just pick the highest-probability chunks, but must consider the probabilistic dependencies among chunks.  Perhaps surprisingly, the Bayes rule can still be obtained in polynomial time using some interesting probabilities ([Waegemans et al., 2014](http://jmlr.org/papers/volume15/waegeman14a/waegeman14a.pdf)) that we actually could still compute using finite-state dynamic programming \u2014 but that is one quantum too complicated for this assignment.  We don't want to fall back on brute force as in homework 1, either, because it would be astronomically slow: we'd have to iterate over all joint chunkings of the entire test corpus.\n",
    "\n",
    "<a name=\"proxy\"></a>\n",
    "Thus, as a \"proxy\" for $F_1$, we will use a different reward measure that is related:\n",
    "$$R = \\text{true_pos} - \\lambda \\cdot \\text{false_pos}$$\n",
    "This is a linear function and doesn't present the same computational difficulties.  The expected $R$ for the corpus is now just a sum over all the sentences \u2014 and it will be relatively easy to use a weighted finite-state machine to compute the expected reward for each sentence.  We will construct a decision agent that maximizes expected $R$ rather than expected $F_1$.\n",
    "\n",
    "The justification is that $R$ is a fairly reasonable reward measure on its own.  The first term emphasizes recall (encourages positives in hopes of getting true positives).  The second term emphasizes precision (discourages positives for fear of getting false positives).  Thus, by controlling the relative weight of these two terms, $\\lambda$ indirectly controls the relative importance of precision and recall in our evaluation.  \n",
    "\n",
    "We could simply pick a $\\lambda$ value and evaluate our chunking system using $R$.  However, it is conventional to evaluate chunking systems using $F_1$ (and maybe for good reason, since $F_1$ strongly penalizes systems with very low precision or very low recall).  Also, it's not clear what $\\lambda$ value we should use, whereas $F_1$ explicitly specifies a particular standard tradeoff between precision and recall.  (The use of $F_1$ is meant as an application-independent convention.  If you have a real-world application that calls for a different tradeoff, you could use [$F_\\beta$ for some other $\\beta$](https://en.wikipedia.org/wiki/F1_score#Formulation).)\n",
    "\n",
    "So we will in fact evaluate on test data using $F_1$.  To get good test performance, we'll choose $\\lambda$ to maximize the $F_1$ measure that our decision agent achieves on dev data.  In other words, although we're using the wrong kind of Bayes rule \u2014 a Bayes rule for $R$ rather than $F_1$ \u2014 we do have a free hyperparameter in the definition of $R$, and we tune it to trade off precision and recall in the way that $F_1$ likes the best. \n",
    "\n",
    "You should fill in the `IobTask0.reward` method above, which computes $R$ given $\\boldsymbol{y}$ and $\\boldsymbol{a}$.  \n",
    "\n",
    "Later, we'll construct an FST that can compute `reward` for any $\\boldsymbol{y}$ and $\\boldsymbol{a}$.  This FST will let you consider all the possible $\\boldsymbol{y}$ and $\\boldsymbol{a}$ values using dynamic programming rather than brute force."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "e4c7bc86-52bb-468e-81ce-5c66ce053972",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# two false positives, then two true positives\n",
    "assert 0 == task0.reward(xx=None, \n",
    "                         aa=('O','B','I','B','B','O','B','I','I'), \n",
    "                         yy=('O','B','I','I','B','O','B','I','I'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "d7e0f45f-9aa8-48f4-a227-3976070f3a81",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# experiment some more here with `reward_F1_triple`, `F1`, and `reward`\n",
    "### STUDENTS START\n",
    "raise NotImplementedError()  # REPLACE ME\n",
    "### STUDENTS END\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "d9beeabc-f240-4a1c-b3ee-b087927e49c2",
    "deletable": false
   },
   "source": [
    "The existing method `DecisionAgent.test` calls `reward`, so it will compute the *proxy* reward on the test set.  Let's patch the `DecisionAgent` class to add a new method, so that all decision agents will also know how to compute $F_1$ on the test set.  This patch will be inherited by all subclasses and instances of `DecisionAgent`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "5bf38067-b1f5-4b99-8fde-e42ca352270f",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def test_F1(self, dataset):\n",
    "    \"\"\"\n",
    "    Run the decision rule on all the examples in `dataset` and return the F1 score.\n",
    "    \"\"\"\n",
    "    counts = np.zeros(3)  # return true, pos, true_pos\n",
    "    for c, (xx, oo, yy) in enumerate(dataset):\n",
    "        aa = self.decision(xx=xx, oo=oo)\n",
    "        counts += self.task.reward_F1_triple(aa=aa, xx=xx, yy=yy)   # running total\n",
    "        if c % 50 == 49: sys.stdout.write('\\r\\tevaluated reward on {} examples'.format(c+1))\n",
    "    sys.stdout.write('\\n')\n",
    "\n",
    "    # compute the f1 score.  We use a rearranged form of the formula, to reduce the chances of division by 0.\n",
    "    true, pos, true_pos = counts\n",
    "    \n",
    "    return F1(true, pos, true_pos)\n",
    "\n",
    "DecisionAgent.test_F1 = test_F1    # patch DecisionAgent to add a new method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "cc6e840b-371b-463d-ab03-06ff199d31f6",
    "deletable": false
   },
   "source": [
    "# Part 2 \u2014 Modeling with a Conditional Random Field\n",
    "\n",
    "**Model / Features:**\n",
    "<img src=\"images/crf.png\" width=750px ></img>\n",
    "\n",
    "Our model is a CRF: $$p(\\boldsymbol{y} \\mid \\boldsymbol{x}) = \\frac{1}{Z(\\boldsymbol{x})} \\exp G(\\boldsymbol{x},\\boldsymbol{y}) = \\frac{1}{Z(\\boldsymbol{x})} \\left(\\exp \\boldsymbol{\\theta}\\cdot\\text{features}(\\boldsymbol{x},\\boldsymbol{y})\\right)$$ \n",
    "Each of our features is a **count feature** that returns the count of some particular configuration in $(\\boldsymbol{x},\\boldsymbol{y})$.  Thus, $G(\\boldsymbol{x},\\boldsymbol{y})$ is the total weight according to $\\boldsymbol{\\theta}$ of all the configurations that appear in $(\\boldsymbol{x},\\boldsymbol{y})$.\n",
    "\n",
    "We use the following features:\n",
    "* Tag-tag features.  For example, the `I_O` feature fires on every `I O` bigram (which rewards or punishes each named entity that ends in the middle of a sentence).  Exactly one tag-tag feature fires at each position $j$, which adds a term $g_{tt}(y_j,y_{j+1})$ into the score, or equivalently multiplies a factor $\\psi_{tt}(y_j,y_{j+1}) = \\exp g_{tt}(y_j,y_{j+1})$ into the unnormalized probability, as shown in the figure.\n",
    "    * Tag-tag features also fire at the boundaries of $\\boldsymbol{y}$.  For example, the `I_EOS` feature fires if there is an `I EOS` bigram (which rewards or punishes any named entity that ends at the end of a sentence).  The factors contributed by these two features are labeled in the figure as $\\psi_{\\text{BOS}}$ and $\\psi_{\\text{EOS}}$.\n",
    "* Tag-word features.  For example, the `B_brussel` feature fires for every token of the word `brussel` that starts a chunk.  Exactly one tag-word feature fires at each position $j$, which adds a term $g_{tw}$ into the score, or equivalently multiplies a factor $\\psi_{tw} = \\exp g_{tw}$ into the unnormalized probability, as shown in the figure.\n",
    "\n",
    "The above factors are analogous to the transition and emission probabilities of HMMs.  This feature set deliberately limits the dependencies among the tags $y_j$ to be bigram dependencies.  This ensures that there exists a simple \"trellis\" WFSA that can score every possible $\\boldsymbol{y}$ \u2014 exactly the same WFSA as for an HMM (with about $J\\cdot|\\mathcal{Y}|$ states and $J\\cdot|\\mathcal{Y}|^2$ arcs).  Inference will take time proportional to the size of the trellis.\n",
    "\n",
    "Recall that the features in a CRF model $p(\\boldsymbol{y} \\mid \\boldsymbol{x})$ can depend freely on any property of $\\boldsymbol{x}$.  This does not change the topology of the trellis, but only makes its the weights dependent on $\\boldsymbol{x}$.  To illustrate some of this generality, we also include:\n",
    "* Tag-previous-word features.  For example, the `B_brussel_-1` feature fires for every chunk that is immediately preceded by the word `brussel`.  At each position, the factor contributed by these features is labeled as $\\psi_{tw_{-1}}$.  Note that the previous word may be $\\text{BOS}$.\n",
    "\n",
    "In short, we have $$p(\\boldsymbol{y} \\mid \\boldsymbol{x}) = \\frac{1}{Z(\\boldsymbol{x})} \\left(\\prod_{j=0}^{J} \\psi_{tt}(y_j,y_{j+1})\\right) \\left(\\prod_{j=1}^J \\psi_{tw}(y_j,x_j) \\psi_{tw_{-1}}(y_j,x_{j-1})\\right)$$\n",
    "\n",
    "Many other features could be added in principle.  Obviously, we could use not just $\\psi_{tw_{-1}}$ but also $\\psi_{tw_{-2}}, \\psi_{tw_{+1}}, \\psi_{tw_{+2}}$.  We could use features that relate tag $y_j$ to the spelling of word $x_j$ and to its position $j$ in the sentence.  \n",
    "\n",
    "(Remark: A more advanced move would be to have features that examine entire chunks, not just tag unigrams and bigrams.  For example, a feature might fire on every span $\\boldsymbol{x}_{i:j}$ that appears in a list of university names and is marked as a chunk by $\\boldsymbol{y}$.  Such a \"segmental CRF\" goes beyond the bigram features shown above, and in general would require us to increase the trellis size and the runtime of inference from $O(J)$ to $O(J^2)$.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "71a31977-9d7d-44e2-b0c9-a3daf2f7ab96",
    "deletable": false
   },
   "source": [
    "## Implementing the model\n",
    "\n",
    "As the formula makes clear, a CRF is just a Boltzmann distribution, expressed as a product of factors $\\psi$ that refer to different (possibly overlapping) portions of the output structure.  Thus, our implementation will extend the `BoltzmannModel` class from homework 1.  (This means we are still using brute-force algorithms \u2014 we'll fix that later.)\n",
    "\n",
    "We'll define our new subclass in such a way that it could be used for *any* tagging task \u2014 not just IOB tagging, but also part-of-speech tagging or syllable stress tagging.  There is a clean separation of concerns between the task setting above and the probability model below:\n",
    "* The choice of the IOB alphabet, the restriction on legal IOB tag sequences, and the special meanings of the IOB tags show up only in the task setting and its reward function.\n",
    "* Conversely, the bigram CRF structure and features show up only in the probability model. \n",
    "\n",
    "So it's possible to mix-and-match different tagging tasks with different tagging models.\n",
    "\n",
    "Again, we'll start with a brute-force model.  So just fill in the implementation of `score_with_gradient` below, remembering that the gradient $\\nabla G_{\\boldsymbol{\\theta}}$ is just the vector of feature counts.  You will also have to fill in `initialize_params` to set $\\boldsymbol{\\theta} = 0$.  You should have $(|\\boldsymbol{\\mathcal{Y}}|^2 + 2 \\cdot |\\boldsymbol{\\mathcal{Y}}|) + |\\boldsymbol{\\mathcal{X}}| \\cdot |\\boldsymbol{\\mathcal{Y}}| + (|\\boldsymbol{\\mathcal{X}}| + 1) \\cdot |\\boldsymbol{\\mathcal{Y}}|$ parameters in your model, one for each of the features described above.\n",
    "\n",
    "#### Managing the parameters\n",
    "\n",
    "You should use an attribute called `.params`, as in homework 1.  (Homework 1 actually made it a property, but an ordinary attribute is simpler and will work better with some of the designs below.  As mentioned above, we changed `Probability.params` accordingly in `seq2class_homework1.py`, and so should you.)  \n",
    "\n",
    "But what kind of object is the value of `.params`?  How you store the parameters is up to you.  Some options:\n",
    "* You could stick with a single parameter vector $\\theta$ (exactly like `LogLinearModel` in homework 1).\n",
    "    * You could then decide to store the tag-tag parameters in one part of $\\theta$ and the tag-word parameters in another part.  By integerizing the tags and words, and using a systematic layout, you can use simple arithmetic to compute the distinct integer index for each parameter.  This is essentially a customized integerizer for the parameter names.\n",
    "    * Alternatively, instead of calculating indices via arithmetic, you could use a generic `Integerizer` object to map entire parameter names such as (tag, word) tuples to distinct integers that index the parameter vector.  This is easier, more elegant, probably less error-prone, and more reusable, if a bit slower.  \n",
    "        * *Caution:* When naming your parameters, be careful not to confuse the word 'I' with the tag 'I'.  In the same spirit, the boundary markers should not be represented as strings `BOS` and `EOS`, to prevent confusion if those strings also serve as tags or words.  (A good choice is to instead use the Python object `None` for any tag or word that is beyond the edge of the string, e.g., `xx[0]==None`, `yy[0]==None`, `yy[len(yy)]==None`.)\n",
    "* Perhaps more elegantly, instead of forcing the parameters into a vector shape, you could use distinct parameter *matrices* for the tag-tag feature weights and the tag-word feature weights.  Then the `params` object should store these matrices.  You will need a new class for this (call it `BigramCrfParams`).\n",
    "    * The gradient has the same shape as the parameter vector, so gradient would be stored in an object of the same class.  This class should implement at least `__isub__`  and `__rmul__` [methods](https://docs.python.org/3/reference/datamodel.html#emulating-numeric-types), which will be called when `SGDTrainer` invokes `-=` and `*` to subtract a multiple of the gradient from the current `params`.  See `paramdict.py` for an illustration of how to do this.\n",
    "* In fact, as long as `params` is a new kind of object, that object doesn't even have to contain matrices at all.  It could just be a generic `ParamDict` (defined above) that maps parameter names directly to their weights.  `ParamDict` is not specific to our CRF, but could be used for any model, since it is very flexible: unlike `BigramCrfParams`, it doesn't commit to using a particular collection of matrices.  Just as with the `Integerizer` solution above, this elegant generic solution is easier than the customized solution but may be a bit slower.\n",
    "\n",
    "#### Sparsity\n",
    "\n",
    "If you wish to be asymptotically efficient, make use of *sparse* vectors or matrices.  The CRF's *parameters* can be naturally and efficiently stored in dense vectors or matrices.  However, the SGD *gradient* on a single training example $(\\boldsymbol{x},\\boldsymbol{y})$ will be sparse, because only a few feature weights affect $p_\\theta(\\boldsymbol{y}\\mid\\boldsymbol{x})$; the gradient with respect to the other parameters is therefore 0.  \n",
    "\n",
    "Exploiting sparsity means that you shouldn't waste any time on all those zeroes.  You want the runtime for each training example to be proportional to the number of features that actually fire on the example, not the total number of features.  For example, an SGD step on a 20-word training sentence should adjust the tag-word parameters for only the \u2264 20 distinct words in that sentence, which might be a tiny subset of the full parameter vector if the vocabulary is large.  Using a sparse gradient vector is a way to avoid storing and adding useless zeroes for the rest of the parameters.  \n",
    "\n",
    "Here are some options if you want to try a sparse solution.  Be warned that in Python, these solutions *might* be slower than using dense numpy arrays.  The dense numpy array operations are highly optimized: they make low-level library calls that exploit hardware parallelism (vector processing on the CPU).  The sparse solutions are *asymptotically* faster, but they have to run explicit loops, which has overhead, especially in an interpreted language like Python.\n",
    "\n",
    "* The `ParamDict` solution is naturally sparse.\n",
    "* You could try SciPy's implementation of sparse vectors and matrices, `scipy.sparse.dok_matrix`.\n",
    "* Here's a fast data structure that mixes dense and sparse.  (This is what Jason would probably do in a streamlined C++ implementation.)  Store the params and gradient in parallel arrays \u2014 which allows rapid random access to the integerized parameters and their partial derivatives \u2014 but also pair the gradient array with a list of the indices of its (few) nonzero elements.  Thanks to this list, you can make each SGD step take time proportional to the number of features used on this step:\n",
    "    * To avoid creating a new gradient array (with lots of zeros) for each training example, `BigramCrfModel` should just reuse the same gradient array for every call to `score_with_gradient`.\n",
    "    * Taking an SGD step only requires visiting the nonzero elements.  \n",
    "    * These elements can be reset to zero at the start of the next call of `score_with_gradient`.  \n",
    "        * Better yet, you can write a specialized method that handles `params -= stepsize * gradient; gradient = 0` all at once.  This method iterates only once through the nonzero elements of gradient, applying them to params and resetting them to 0 as they are applied.  This avoids having to iterate again later to reset them.  It also means that visiting the same element a second time will have no additional effect (since it's been reset to 0), which means that you can add the index to the list without checking for duplicates.  (You can prevent most duplicates cheaply by declining to add an index when you update a non-0 element, since that element will already be on the list.  However, a duplicate will still arise in the rare case of updating from 0 to non-0 back to 0 to non-0; so it's important to know that this will not introduce an error.)\n",
    "    * To fit with the rest of the object-oriented design, you should create a simple class to represent the gradient vector as an (array, list) pair.\n",
    "\n",
    "#### The vocabulary of word types\n",
    "\n",
    "Because the model uses tag-word and tag-previous-word features, the number of features depends on the size of the vocabulary.  Some of the strategies above need to know the size of the vocabulary in advance.  Thus, your constructor for `BigramCrfModel` should take the vocabulary as an argument.  This can be any collection of word types or tokens (generally derived from training data).  The constructor will probably want to turn it into a `Set` or an `Integerizer`.  If word $w_i$ is not in the vocabulary (OOV), then no tag-word feature will fire at position $i$. \n",
    "\n",
    "The `ParamDict` strategy has the nice property that you *don't* actually need to know the full set of parameters in advance.  New parameters will start out as 0 when first accessed, and will be added lazily to the dictionary when first modified.  In fact, this would make it easy to implement an infinite-vocabulary model, where the `ParamDict` only stores nonzero weights for the finitely many words observed in training so far.  For this homework, however, you should respect the `vocab` argument to the constructor, which defines a finite vocabulary.  So you should explicitly avoid computing features on OOV words, although it is still ok to add the in-vocabulary features lazily to the `ParamDict` as you encounter them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "a025d934-1be9-49fe-9510-de00227e4cfa",
    "deletable": false
   },
   "source": [
    "Complete the `BigramCrfModel0` class below, still following the framework of Homework 1.  Later on in this notebook, we'll extend it to `IobTask`, a more efficient subclass that provides a finite-state description of the probability distribution, in order to allow dynamic programming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "e34627ee-ae00-4da8-84be-11450eeb7b22",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "class BigramCrfModel0(BoltzmannModel):\n",
    "    \"\"\"\n",
    "    A 1st-order CRF model with a particular feature set described in the assignment.\n",
    "    The tag types are given by task.Y_alphabet.\n",
    "    The word types are supplied to the constructor via an iterable collection of\n",
    "    word types or tokens.\n",
    "    \"\"\"\n",
    "    def __init__(self, task, *, vocab):\n",
    "        ### STUDENTS START\n",
    "        raise NotImplementedError()  # REPLACE ME\n",
    "        ### STUDENTS END\n",
    "        super().__init__(task)   # among other things, this calls `initialize_params`\n",
    "\n",
    "    def initialize_params(self):\n",
    "        ### STUDENTS START\n",
    "        raise NotImplementedError()  # REPLACE ME\n",
    "        ### STUDENTS END\n",
    "        \n",
    "    def score_with_gradient(self, *, xx, yy):\n",
    "        \"\"\"\n",
    "        Compute the feature vector given `xx` and `yy` sequences.\n",
    "        Then return the score and its gradient (i.e., the feature vector).\n",
    "        \"\"\"\n",
    "        ### STUDENTS START\n",
    "        raise NotImplementedError()  # REPLACE ME\n",
    "        ### STUDENTS END\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "83088aed-2d01-4f74-9582-9ccad96b8f52",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# A little example to check that the right features are extracted.\n",
    "# Since we're using the initial parameter vector of 0, the score will be 0, \n",
    "# but the gradient will show the feature counts, which you can check manually.\n",
    "model0 = BigramCrfModel0(task0,vocab=['foo','bar'])   \n",
    "model0.score_with_gradient(yy=('B','I','I','O'),xx=('bar','bar','oov','foo'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "4ac4f496-47ea-4268-a18e-b9b168af3e39",
    "deletable": false
   },
   "source": [
    "## Trying out the model using brute-force methods\n",
    "\n",
    "This is enough to get our methods from Homework 1 running.  They are slow brute-force methods, so let's train on `train-small` and evaluate the performance on `dev-small`.  We do have to add a way of testing using $F_1$ reward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "6fb4681c-ddbe-4933-b825-799d4dbbe42a",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Define the vocabulary.\n",
    "import itertools\n",
    "def vocab_from_data(examples):\n",
    "    \"\"\"\n",
    "    Extract a vocabulary from the dataset.  \n",
    "    Currently we use all words that appear at least once in the dataset.\n",
    "    \"\"\"\n",
    "    # Iterate through all words in all input sentences (xx), and construct a set. \n",
    "    return set(itertools.chain.from_iterable(map((lambda e: e.xx), examples)))  \n",
    "\n",
    "data_small = list(iterate_data('train-small'))\n",
    "vocab_small = vocab_from_data(data_small)\n",
    "(len(vocab_small), list(islice(vocab_small,10)))  # size of vocab and 10 words from it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "5cbef4d5-d0c9-4eb9-9cec-39ab24800199",
    "deletable": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "399e2347-9e69-4705-9a08-5c1501195e79",
    "scrolled": true,
    "deletable": false
   },
   "outputs": [],
   "source": [
    "class TrainableBigramCrfModel0(L2LogLikelihood, BigramCrfModel0):   \n",
    "    pass   # inherit everything from the two parents\n",
    "\n",
    "model0 = TrainableBigramCrfModel0(task0, \n",
    "                                  vocab=vocab_small, \n",
    "                                  regularization_coeff=15,\n",
    "                                  num_examples=len(data_small))\n",
    "\n",
    "sgd_trainer = SGDTrainer(epochs=10)\n",
    "%time sgd_trainer.train(model0, data_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "da3b7105-254a-4ef8-a83d-e907b766839e",
    "deletable": false
   },
   "source": [
    "Check our F1 score on short sentence development data set.  Decoding is performed using the brute-force decision agent, which iterates through the entire domain of each $\\mathcal Y_x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "4fae34c4-6db3-4da6-a661-9441d3eb19b2",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "agent0 = ViterbiAgent(task0, model0)\n",
    "agent0.test_F1(iterate_data('dev-small'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "d6472907-226d-4d83-b1c2-bbc053d11e36",
    "deletable": false
   },
   "source": [
    "## Part 3 \u2014 Finite-state methods\n",
    "\n",
    "We are now going to review FSTs, and go through a small tutorial of working with FSTs in Python.  Our eventual goal is to use efficient FST operations to implement a Bayes rule for the chunking task under our CRF model.\n",
    "\n",
    "#### If you have not already done so, install our OpenFST Python library:\n",
    "   ```bash\n",
    "   source ~/path/to/anaconda3/bin/activate  # activate our anaconda environment\n",
    "   which python  # should print /home/USERNAME/path/to/anaconda3/bin/python\n",
    "   pip install --upgrade 'git+https://github.com/matthewfl/openfst-wrapper.git'\n",
    "   # ^^ this will take about 5-10 minutes (tested on ugrad machines)\n",
    "   ```\n",
    "\n",
    "Throughout this assignment, you may find it helpful to reference OpenFST's available operations **[here](http://www.openfst.org/twiki/bin/view/FST/FstQuickTour#Available_FST_Operations)**.\n",
    "\n",
    "Additionally, you can find the documentation on mfst, our FST library, included in its source **[here](https://github.com/matthewfl/openfst-wrapper/blob/master/mfst/__init__.py)**.\n",
    "  \n",
    "Note that OpenFST and mfst refer to all finite-state machines as FSTs.\n",
    "However, in this notebook, we will use FSA to refer to the special case of a finite-state *acceptor*,\n",
    "and reserve FST for finite-state *transducers* (whose inputs and outputs may be different).  This serves as some documentation of the intended types.\n",
    "  \n",
    "  \n",
    "<span style='color:red;font-size: 20px'>Warning:</span> OpenFST has some of the <u>*worst*</u> error handling.  If you do something wrong, there is a decent chance that you are just going to get the garbage as the output.  You should attempt to sanity check any operations with OpenFST using small examples.  Some functions will fail to terminate if you give them the wrong input.  You will have to check the OpenFST documentation to determine if there are any restrictions on what a function can handle or if the runtime of a method will be *acceptable*.  OpenFST provides `FST().verify` which you might find helpful in performing basic sanity checks when debugging your FSTs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "3ac3f33d-568e-434a-8e0b-ee3e14c83eba",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from mfst import ( FST, AbstractSemiringWeight, PythonValueSemiringWeight, \n",
    "                       RealSemiringWeight, BooleanSemiringWeight, MaxPlusSemiringWeight )\n",
    "except ImportError:\n",
    "    print('Error: Need to install mfst package; see instructions in notebook')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "9abec9a9-9e81-420a-9b2d-6ecf6a9018db",
    "deletable": false
   },
   "source": [
    "As a simple example, here's a simple FST with two states, `start` and `end`.  There is a single arc between these two states with a label of `i:o/1`.  This arc can be traversed on input character `i`, which results in emitting output character `o` and incurring a weight of `1`.\n",
    "\n",
    "OpenFST internally uses integers as its input and output symbols, with `0` representing \u03b5 (the empty string `''`).  However, the mfst package will also let you specify characters such as `i` or `\u03b8`; a character will be automatically [converted](https://docs.python.org/3/library/functions.html#ord) to an integer, namely its Unicode code point.  (If you specify any characters when creating the FST, the integer labels will be [converted back](https://docs.python.org/3/library/functions.html#chr) to characters when the FST is drawn.) \n",
    "If you want your input and output symbols to come from some other set of objects, such as words, then you should convert them to integers yourself, using an `Integerizer` that has been initialized with `''` as its first object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "f425e85d-3e76-43d2-909b-5eb4935a4b15",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "myfst = FST()                    # new FST\n",
    "start = myfst.add_state()        # add a state (represented as an integer)\n",
    "myfst.initial_state = start      # designate it as the initial state\n",
    "end = myfst.add_state()          # add another state\n",
    "myfst.set_final_weight(end, 1)   # designate it as a final state, with stopping weight of 1\n",
    "myfst.add_arc(start, end, input_label='i', output_label='o', weight=1)   # add an edge labeled i:o/1\n",
    "\n",
    "# look at the FST\n",
    "myfst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "88c8e452-5449-43e1-81f8-d16be1eee8d0",
    "deletable": false
   },
   "source": [
    "The initial state is shown in green, and final states (other than the initial state) are shown in red.\n",
    "\n",
    "The default weight for both `set_final_weight` and `add_arc`is `1` (in general, the semiring's \u2460 value) , so the above calls could actually have been simplified to omit the weight argument.  As you can see, **default weights are not shown in the drawing**.\n",
    "\n",
    "To check your understanding, create a cycle by adding an edge from the final state back to the initial state, labeled with `\u03b5:z/2`.  Remember that \u03b5 is represented by the integer label 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "dac0b9ec-64e1-4c10-961b-084433d8389f",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "### STUDENTS START\n",
    "raise NotImplementedError()  # REPLACE ME\n",
    "### STUDENTS END\n",
    "myfst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "e4028886-8ce2-434a-acad-fe2f6399d8d3",
    "deletable": false
   },
   "source": [
    "You can use some of [mfst](https://github.com/matthewfl/openfst-wrapper/blob/master/mfst/__init__.py)'s methods to inspect your FST:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "1a154068-3c9a-4b71-ace7-9f3d6779bc18",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "(start,end)  # states are represented by integers, as in the drawing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "4d85cab7-6a74-49a7-ac54-c9fad0e61136",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "myfst.get_final_weight(start)   # start is not a final state in myfst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "a7a9b0d7-28af-42c7-b3ad-2a7f7677dc22",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "myfst.get_arcs(start)  # the arcs leaving start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "146eb2a8-ae57-4c27-a90d-98cbaea199a6",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "myarc = myfst.get_arcs(start)[0]\n",
    "(chr(myarc.input_label), chr(myarc.output_label), myarc.weight.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "96219de8-3b7a-43e4-9d20-71dc043323a3",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "paths = myfst.iterate_paths()    # iterator over all paths\n",
    "list(islice(paths,10))           # first 10 paths out of infinitely many"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "a65e6aed-1226-4b6f-a85a-e3f4a7510596",
    "deletable": false
   },
   "source": [
    "Recall that an FSA that recognizes a (regular) language $L$ is traditionally implemented as an FST that transduces any string in $L$ to itself (with weight one in the semiring), and rejects any other string in $L$.  \n",
    "\n",
    "As a special convenience, here's a way to construct an unweighted FSA that accepts exactly one string, assigning it the `BooleanSemiringWeight` of `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "ee1f82c0-e0eb-4ec6-8f28-484b883fa791",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "FST('hello')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "fe985b57-aa00-4aaf-9ae5-ec5c45cdc9b9",
    "deletable": false
   },
   "source": [
    "Usually it's fine to use an unweighted FSA, since `mfst` kindly permits you to compose these nicely with machines in other semirings.  However, if you wanted to create a single-string FST in some other semiring, you can do it like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "e7468271-b034-461b-8ed3-ae075eb333f7",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "base_fst = FST(RealSemiringWeight)\n",
    "base_fst.create_from_string('hello')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "489ea34a-5c13-4849-b822-4bde8663a03d",
    "deletable": false
   },
   "source": [
    "Or like this, for an integer sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "d676e4f2-d0bb-41dd-913f-2920e7da19de",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "base_fst.create_from_string( (1234, 1337) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "46b3e9e6-f2fc-4757-8b6e-cccf06146d01",
    "deletable": false
   },
   "source": [
    "Recall that [compose](http://www.openfst.org/twiki/bin/view/FST/ComposeDoc) is the way to feed a string into an FST.  In general, it takes all the output strings of one FST and feeds them as input to a second FST.\n",
    "If no output of the first FST is accepted by the second FST, then we will get an empty FST as the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "fe205bcc-a600-4211-ab6f-990bf045f09c",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "FST('hello').compose(myfst)  # hello is not in the domain of myfst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "d3e94666-46c0-4e00-8f33-5b49ff318cc5",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "FST('i').compose(myfst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "b9b4d48b-104a-4e2f-b469-f50e5366a590",
    "deletable": false
   },
   "source": [
    "Using `myfst` from above, what input string will generate the output `ozozo`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "d23d14d6-7fc5-44fb-80b6-9228d6e449d3",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "### STUDENTS START\n",
    "### input_string = FILL IN\n",
    "raise NotImplementedError()  # REPLACE ME\n",
    "### STUDENTS END\n",
    "FST(input_string).compose(myfst).get_unique_output_string()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "0c7bbd55-2b68-4e49-a102-adc1dfd6865b",
    "deletable": false
   },
   "source": [
    "### Paths through FSTs\n",
    "\n",
    "As we will see below, with the right choice of semiring, OpenFST's [`shortest_path`](http://www.openfst.org/twiki/bin/view/FST/ShortestPathDoc) method will run the Viterbi algorithm for finding the best path.\n",
    "\n",
    "First, here is [the hot-cold lattice from the NLP class](https://www.cs.jhu.edu/~jason/papers/#eisner-2002-tnlp)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "6ae6399f-372c-40f4-8264-a02485bcebb5",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def build_HC_fsa(fsa, n=3, same_weight=1, change_weight=1):\n",
    "    \"\"\"\n",
    "    Build a weighted FSA on weather sequences.  \n",
    "    The first argument should be an existing FSA to which we will add states.\n",
    "    It should be designated as an acceptor, in which case we don't have to specify \n",
    "    `output_label` on the arcs (it will automatically be set equal to `input_label`).\n",
    "    \"\"\"\n",
    "    start = fsa.add_state()\n",
    "    fsa.initial_state = start\n",
    "    h = [fsa.add_state() for i in range(n)]\n",
    "    c = [fsa.add_state() for i in range(n)]\n",
    "    fsa.add_arc(start, h[0], input_label='H')  # default weight of semiring one\n",
    "    fsa.add_arc(start, c[0], input_label='C')\n",
    "    for i in range(n - 1):\n",
    "        fsa.add_arc(h[i], h[i+1], input_label='H', weight=same_weight)\n",
    "        fsa.add_arc(c[i], c[i+1], input_label='C', weight=same_weight)\n",
    "        fsa.add_arc(h[i], c[i+1], input_label='C', weight=change_weight)\n",
    "        fsa.add_arc(c[i], h[i+1], input_label='H', weight=change_weight)\n",
    "    fsa.set_final_weight(c[-1])\n",
    "    fsa.set_final_weight(h[-1])\n",
    "\n",
    "weather = FST(acceptor=True)\n",
    "build_HC_fsa(weather, same_weight=2, change_weight=5)\n",
    "weather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "3297bfa8-d615-4e08-8da0-71d2500f3a03",
    "deletable": false
   },
   "source": [
    "### The Tropical semiring\n",
    "\n",
    "Weights in the above FSA are simply arbitrary Python objects equipped with their built-in `+` and `*` operators (that is, `__add__` and `__mul__` methods).  This is mfst's default semiring, `PythonValueSemiringWeight`.  \n",
    "\n",
    "But if we want to find the best path, we need to instead use the $(\\min,+)$ semiring.  This is commonly called the \"tropical semiring\" (in homage to Brazilian researcher Imre Simon).\n",
    "\n",
    "To review the semiring, fill in the table below.  This is technically speaking not just a semiring but a \"division semiring\" -- the left-division operation included below is needed by the determinization and minimization algorithms for weighted FSAs and FSTs.  The $\\le$ [operation](http://www.openfst.org/twiki/bin/view/FST/FstAdvancedUsage#Natural_Orders) is defined in terms of $\\oplus$ (see below); in this case it happens to be a total order, so the weight of the shortest path is well-defined, and the semiring is said to have the [path property](http://www.openfst.org/twiki/bin/view/FST/FstWeightRequirements)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "c6b47543-f10b-4f80-b7e4-ab6527c01456",
    "deletable": false
   },
   "source": [
    "$$\n",
    "\\begin{array}{|c|c|c|c|} \\hline\n",
    "\\text{Semiring operation} & \\text{Symbol} & \\text{Axioms} & \\text{Definition in tropical semiring} \\\\ \\hline\n",
    "\\text{Zero} & \u24ea & \u24ea \\oplus a = a  & \\infty \\\\\n",
    "& & \u24ea\\otimes a = a \\otimes \u24ea = \u24ea \\\\ \\hline\n",
    "\\text{One} & \u2460 & \u2460 \\otimes a = a \\otimes \u2460 = a & \\color{red}{\\text{FILL IN}} \\\\ \\hline\n",
    "\\text{Add} & \\oplus & \\text{associative, commutative} & c = \\text{min}(a, b) \\\\ \\hline\n",
    "\\text{Multiply} & \\otimes & \\text{associative, distributive over $\\oplus$} & \\color{red}{\\text{FILL IN}} \\\\ \\hline\n",
    "\\text{Left-divide} & {}^{-1} & c = a^{-1}b \\Rightarrow a \\otimes c = b& \\color{red}{\\text{FILL IN}} \\\\ \\hline\n",
    "\\text{Compare} & \\leq & a \\le b \\iff a \\oplus b = a & \\color{red}{\\text{FILL IN}} \\\\ \\hline\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "ff8ae8d6-16c6-45c7-bd39-28ee1194a876",
    "deletable": false
   },
   "source": [
    "To check your understanding, what would change in these definitions if you were looking for the path of *maximum* total weight instead of *minimum* total weight? \n",
    "\n",
    "**Answer**: <span style='color:red'>FILL IN</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "1646ea9e-2502-4c7d-b513-2fd88ccd3b3a",
    "deletable": false
   },
   "source": [
    "Now let's implement the semiring in Python, so you can see how that's done.  (See [semirings.py](https://github.com/matthewfl/openfst-wrapper/blob/master/mfst/semiring.py) for more examples.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "84dfc7b9-0017-488a-94c4-34ac092bd17f",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "class TropicalSemiring(RealSemiringWeight):\n",
    "    \n",
    "    # tell OpenFST that <= is a total order (the \"path property\")\n",
    "    semiring_properties = 'path'  \n",
    "    \n",
    "    # let self.value be the path length of this edge\n",
    "    \n",
    "    def __init__(self, v):\n",
    "        super().__init__(v)  # sets self.value = v\n",
    "            \n",
    "    def __add__(self, other):\n",
    "        # return a new instance of TropicalSemiring with value: self (+) other\n",
    "        ### STUDENTS START\n",
    "        raise NotImplementedError()  # REPLACE ME\n",
    "        ### STUDENTS END\n",
    "    \n",
    "    def __mul__(self, other):\n",
    "        # self (*) other\n",
    "        ### STUDENTS START\n",
    "        raise NotImplementedError()  # REPLACE ME\n",
    "        ### STUDENTS END\n",
    "    \n",
    "    def __div__(self, other):\n",
    "        # self (/) other\n",
    "        ### STUDENTS START\n",
    "        raise NotImplementedError()  # REPLACE ME\n",
    "        ### STUDENTS END\n",
    "        \n",
    "    def __eq__(self, other):\n",
    "        return isinstance(other, TropicalSemiring) and self.value == other.value\n",
    "    \n",
    "    def __hash__(self):  # __hash__ is required if defining __eq__\n",
    "        return hash(self.value)\n",
    "    \n",
    "TropicalSemiring.zero = TropicalSemiring(math.inf)\n",
    "# TropicalSemiring.one = FILL IN\n",
    "### STUDENTS START\n",
    "raise NotImplementedError()  # REPLACE ME\n",
    "### STUDENTS END\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "e83de982-a0a8-491f-8a76-3a2a0587ebcc",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def test_semiring(semiring):\n",
    "    # some basic sanity checks for the semiring\n",
    "    one = semiring.one\n",
    "    zero = semiring.zero \n",
    "    two = one + one\n",
    "    assert one * zero == zero\n",
    "    assert two * zero == zero\n",
    "    assert one + zero == one\n",
    "    assert two + zero == two\n",
    "    assert two / two == one\n",
    "    \n",
    "test_semiring(TropicalSemiring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "b3794063-2972-450a-9839-534451f64558",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# check TropicalSemiring operations\n",
    "(\n",
    "    TropicalSemiring.zero + TropicalSemiring.one, \n",
    "    TropicalSemiring.zero * TropicalSemiring.one, \n",
    "    TropicalSemiring(1),                        # not equal to TropicalSemiring.one\n",
    "    TropicalSemiring(6) / TropicalSemiring(2)   # not equal to TropicalSemiring(6/2)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "b98a9169-01dc-495b-b255-0e69c4e83a82",
    "deletable": false
   },
   "source": [
    "Now let's re-build the weather FSA using `TropicalSemiring` weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "9c83b4f3-4d96-46af-a40b-2604b49d4271",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "weather = FST(TropicalSemiring, acceptor=True)\n",
    "build_HC_fsa(weather, same_weight=2, change_weight=5)\n",
    "print(weather.semiring)\n",
    "print(weather)\n",
    "weather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "c8fb9f1b-dbb2-4c32-bd05-f0e81c606258",
    "deletable": false
   },
   "source": [
    "Again, you can extract all paths labeled with a particular input string by composing that string with the FSA or FST.  The weight of a path is the product of the weights along the path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "027184e0-2aec-4657-9182-5d20f9c268af",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "weather.compose(FST('HCC'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "f5f85a50-fc28-4bfb-aa92-9cb168960d76",
    "deletable": false
   },
   "source": [
    "### More finite-state operations\n",
    "\n",
    "[**Weight pushing**](http://www.openfst.org/twiki/bin/view/FST/PushDoc) redistributes the weights along the paths.  Every path still has the same weight as before (defined by $\\otimes$).  However, pushing the weights toward the initial state means that we will \"take the pain\" as early as possible on the path.  Let's see how it works on the hot-cold FSA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "52bf2499-67e3-409f-b7e6-da159ac0dec6",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "weather.push()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "dd3cf75f-829f-4063-8292-dbc60e613bd9",
    "deletable": false
   },
   "source": [
    "How does pushing work?  In the tropical semiring, suppose the paths *from* a certain state have total weights of 13, 17, 23, and 27.  Reaching that state means that we will incur a future cost of *at least* 13.  The `push` operation will push that guaranteed cost of 13 \"backwards through the state\" so that it instead appears on the paths leading *to* the state.  Now the paths from the state have total weights of only 0, 4, 10, and 14.  \n",
    "\n",
    "Weights are recursively pushed back as far as possible.  Let $\\beta(t)$ denote the total weight of all paths from state $t$ \u2014 where \"total\" uses $\\oplus$, so it is the minimum (e.g., 13) in the case of the tropical semiring.  Formally, the pushing algorithm replaces the weight $w$ on an arc $s \\stackrel{w}{\\rightarrow} t$ with $\\beta(s)^{-1}w \\otimes \\beta(t)$.  Thus, the $w$ arc receives an extra weight of $\\beta(t)$ that has been pushed back through $t$ from all the paths leaving $t$, but then the arc (like all of $s$'s out-arcs) pushes a weight of $\\beta(s)$ back through $s$.\n",
    "\n",
    "The above paragraph handles arc weights but not state weights.  Figure out and explain how the pushing algorithm should handle the weights at initial and final states, where the weight of a path from initial state $a$ to final state $z$ is $\\text{initial_weight}(a) \\otimes \\text{arc_weight} \\otimes \\cdots \\otimes \\text{arc_weight} \\otimes \\text{final_weight}(z)$.  Convince yourself that after this algorithm has been run, all path weights are preserved and we have $\\beta(s) = \u2460$ at all states $s$.  Note that $\\beta(s)$ sums over \"suffix paths\" from $t$: this includes the initial-state weight.\n",
    "\n",
    "<b>Answer:</b> <span style='color:red'>FILL IN</span>\n",
    "\n",
    "You can test your understanding in the notebook below this cell.  Be warned, however, that OpenFST doesn't actually support general initial-state weights.  Rather, it requires a single dedicated initial state whose initial weight is \u2460, and all other states have initial weight of \u24ea.   This involves no loss of generality, since any FST with initial-state weights is equivalent to one in OpenFST's restricted form.  How does this restriction change the pushing construction?\n",
    "\n",
    "<b>Answer:</b> <span style='color:red'>FILL IN</span>\n",
    "\n",
    "Most important, you want the weight of the shortest path in an FSA or FST.  Where can you find that in general after you invoke weight pushing?  Check your answer using the above drawing of `hc_fsa.push()`.\n",
    "\n",
    "<b>Answer:</b> <span style='color:red'>FILL IN</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "c7fca1a8-2256-4c02-b06c-89bab6406d5e",
    "deletable": false
   },
   "source": [
    "Pushing is called as a subroutine in weighted FSA minimization, because two states $s,s'$ that were not originally equivalent (mergeable) can become equivalent after pushing, if they accepted the same weighted suffix language up to a scalar multiplier.  When our FSA is minimized as below, which states are merged?  Were they already equivalent before pushing?  \n",
    "\n",
    "<b>Answer:</b> <span style='color:red'>FILL IN</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "c473b1c9-afa3-4e36-9a0b-15bd2ddb81ed",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "weather.minimize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "673f149f-d30b-4ac2-b282-a285da5d4384",
    "deletable": false
   },
   "source": [
    "What is different if `same_weight` and `change_weight` are equal, as below?  Why?\n",
    "\n",
    "<b>Answer:</b> <span style='color:red'>FILL IN</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "8e265cba-a969-4ea2-943e-6c7cd62d2a57",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "weather2 = FST(TropicalSemiring, acceptor=True)\n",
    "build_HC_fsa(weather2, same_weight=5, change_weight=5)\n",
    "weather2.minimize()   # you may also want to look at the non-minimized version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "ae5cfe80-8033-40ac-8e5b-a18f3788ceae",
    "deletable": false
   },
   "source": [
    "Recall we sometimes have to deal with strings like: `oo='H?H'`, which is compatible with both `HCH` and `HHH`.  For this, you'll need something a little more general than `fst.create_from_string`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "b1566aa9-1faf-4261-8274-85e899b1b869",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def fsa_from_observable(self, oo, alphabet, wildcard='?'):\n",
    "    \"\"\"\n",
    "    Return an FSA that accepts all sequences compatible with `oo`.  The `wildcard`\n",
    "    symbol in `oo` is allowed to match any element of `alphabet`.  The FSA\n",
    "    uses the same semiring and other parameters as `self`.  \n",
    "    \"\"\"\n",
    "    fsa = self.constructor(acceptor=True)\n",
    "    ### STUDENTS START\n",
    "    raise NotImplementedError()  # REPLACE ME\n",
    "    ### STUDENTS END\n",
    "    return fsa\n",
    "\n",
    "FST.create_from_observable = fsa_from_observable    # patch the FST class to add this method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "f4ebc522-11be-4b63-aa99-8a2cdbe117a0",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "fsa_oo = FST(BooleanSemiringWeight).create_from_observable('H?H', 'HC')\n",
    "fsa_oo.verify()   # check that the FSA is well-formed\n",
    "fsa_oo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "d1975356-db54-4f3b-bfa0-1e77d5eca62c",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "posterior = weather.compose(fsa_oo)      # restrict `yy` values to those compatible with observations `oo`\n",
    "posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "d1b77a3d-198c-42c9-a9f7-820e89c019fd",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "print(list(posterior.states))\n",
    "print(posterior.shortest_distance())              # alpha values (total semiring weight of all prefix paths TO each state)\n",
    "print(posterior.shortest_distance(reverse=True))  # beta values (total semiring weight of all suffix paths FROM each state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "bd897d2c-b4fe-4d1c-b30b-3502b997ff72",
    "deletable": false
   },
   "source": [
    "We can run the Viterbi algorithm on the `posterior` FSA to extract the lowest-weight path given our model `weather` and observations `oo`.  This turns out to be labeled `HHH`.  Why does this answer make sense?  Can you guess why OpenFST did not use 0 as the number of the initial state of `fsa_best_yy`?\n",
    "\n",
    "<b>Answer:</b> <span style='color:red'>FILL IN</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "2f254df0-d6d4-4936-b4df-0b3140d0e825",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# 1-best posterior guess of weather given the observation fsa_oo\n",
    "fsa_best_yy = posterior.shortest_path()   \n",
    "display(fsa_best_yy)\n",
    "print(next(fsa_best_yy.iterate_paths()))\n",
    "best_yy = fsa_best_yy.get_unique_output_string()\n",
    "best_yy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "47e52a0f-57fb-43e1-bb91-1512f55294c2",
    "deletable": false
   },
   "source": [
    "### The real semiring\n",
    "<a name=\"ExpectationSemiring\"></a>\n",
    "\n",
    "Finite-state machines are good at defining certain kinds of probability distributions.  We are interested in the distribution over an FSA's paths $\\boldsymbol{y} = y_1 y_2 \\cdots$, where the $y$ symbols denote edges and a final state.  A training data observation $\\boldsymbol{o}$ is in general a regular language that is compatible with multiple possible paths.  We say that $\\boldsymbol{o}$ is a \"fully supervised\" training example when it completely identifies the path.  This is the case when it specifies the path's complete label string (with no wildcards `?`) and the FSA is deterministic (as will be true for our CRF model).\n",
    "\n",
    "To define the unnormalized probabilities of a Boltzmann distribution over the FSA paths, you can weight your FSA in the real semring $(\\oplus,\\otimes) = (+,\\times)$.  The weight of a path $\\boldsymbol{y}$ should be its unnormalized probability $\\tilde{p}(\\boldsymbol{y})$.  Your job is to associate a probability factor $\\psi = \\exp g$ with each edge, so that a path's unnormalized probability $\\tilde{p}(\\boldsymbol{y}) = \\exp G(\\boldsymbol{y}) = \\exp (g(y_1) + g(y_2) + \\cdots) = \\psi(y_1) \\cdot \\psi(y_2) \\cdot \\cdots$ is given by the *product* of the factors on its edges and its final state.  The path's normalized probability is then $\\tilde{p}(\\boldsymbol{y})/Z$, where $Z$ is the total weight of all paths, which can be computed efficiently via the backward algorithm as $\\beta(\\text{initial state})$.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "d0775a16-19b0-4147-9458-05dbba34db55",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# We were using negative log probabilities in the tropical semiring (2 and 5)\n",
    "# Now let's convert those to probabilities in the real semiring (to 3 decimal digits)\n",
    "weather = FST(RealSemiringWeight, acceptor=True)  \n",
    "build_HC_fsa(weather, same_weight=round(math.exp(-2),3), change_weight=round(math.exp(-5),3))\n",
    "weather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "2f50f9b2-0ff6-4c19-a360-cce9ebd9a258",
    "deletable": false
   },
   "source": [
    "Recall that the weight pushing operation tries to ensure that the out-arcs from a node sum to \u2460, which in this case means that they sum to 1.  Thus, it converts this globally normalized FSA to a locally normalized one!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "208032ce-2375-41e4-a62c-3fda0b60fe06",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "weather.sum_paths()   # computes Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "53961022-760a-43d0-9ff1-7f7ba616d646",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "weather.push()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "9404c3cd-570b-4b0e-a728-288d796dbf8f",
    "deletable": false
   },
   "source": [
    "Once the machine is locally normalized, you can sample paths by working left to right from the initial state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "fc8fd3e5-8ac1-4344-af78-25e621a8546b",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "weather.push().random_path(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "e17611a0-9a71-4fb6-838d-9128fb635a11",
    "deletable": false
   },
   "source": [
    "By determinizing a large sample, you can see the number of times each of the 8 possibilities was chosen.  Are there any that didn't show up in the sample?  Why?  (You may want to run this more than once.)\n",
    "\n",
    "**Answer**: <span style='color:red'>FILL IN</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "d695e615-1281-424b-8269-519939b5712d",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "weather.push().random_path(200).determinize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "107e77cd-7ab0-472f-a3a1-db5ce62818e6",
    "deletable": false
   },
   "source": [
    "### The expectation semiring\n",
    "\n",
    "The expectation semiring was introduced by [Eisner (2002)](https://www.cs.jhu.edu/~jason/papers/#eisner-2002-acl-fst) (and further studied by [Li and Eisner (2009)](https://www.cs.jhu.edu/~jason/papers/#li-eisner-2009)) as a way to define not only a distribution as above, but also the expected reward (of a given plan) under that distribution. It lets you associate not only a factor $\\psi$ but also a reward $r$ with each edge, so that the path's reward $R(\\boldsymbol{y}) = r(y_1) = r(y_2) + \\cdots$ is the *sum* of rewards on its edges and its final state.\n",
    "\n",
    "We'll arrange for the weight of a single path $\\boldsymbol{y}$ to be the pair $\\langle \\tilde{p}(\\boldsymbol{y}), \\tilde{p}(\\boldsymbol{y}) R(\\boldsymbol{y}) \\rangle$.\n",
    "We must define $\\oplus$ and $\\otimes$ operations on such pairs such that:\n",
    "* $\\oplus$: The total weight of all paths $\\beta(\\text{initial state})$ is the pair $\\langle \\sum_{\\boldsymbol{y}} \\tilde{p}(\\boldsymbol{y}), \\sum_{\\boldsymbol{y}} \\tilde{p}(\\boldsymbol{y}) R(\\boldsymbol{y}) \\rangle$.  This allows us to get the expected reward by dividing the pair's second element by its first element: $$\\frac{\\sum_{\\boldsymbol{y}} \\tilde{p}(\\boldsymbol{y}) R(\\boldsymbol{y})}{\\sum_{\\boldsymbol{y}} \\tilde{p}(\\boldsymbol{y})} = \\sum_{\\boldsymbol{y}} \\frac{\\tilde{p}(\\boldsymbol{y})}{Z} R(\\boldsymbol{y}) = \\sum_{\\boldsymbol{y}} p(\\boldsymbol{y}) R(\\boldsymbol{y}) = \\mathbb{E}_{\\boldsymbol{y} \\sim p}[R(\\boldsymbol{y})]$$\n",
    "* $\\otimes$: The weight of a single path $\\langle \\tilde{p}(\\boldsymbol{y}), \\tilde{p}(\\boldsymbol{y}) R(\\boldsymbol{y}) \\rangle$ can be obtained as the product of weights $\\langle \\psi(y_i), \\psi(y_i) r(y_i) \\rangle$ associated with its edges and final state.\n",
    "\n",
    "This is accomplished by the definitions below.  Notice that if you ignore the second element of each pair, you have the real semiring.\n",
    "$$\n",
    "\\begin{array}{|c|c|c|c|} \\hline\n",
    "\\text{Semiring operation} & \\text{Symbol} & \\text{Definition in expectation semiring} \\\\ \\hline\n",
    "\\text{Zero} & \u24ea & \\langle 0, 0 \\rangle \\\\ \\hline\n",
    "\\text{One} & \u2460 & \\langle 1, 0 \\rangle \\\\ \\hline\n",
    "\\text{Add} & \\langle \\tilde{p}_1, \\tilde{r}_1 \\rangle \\oplus \\langle \\tilde{p}_2, \\tilde{r}_2 \\rangle & \\langle \\tilde{p}_1+\\tilde{p}_2, \\tilde{r}_1+\\tilde{r}_2 \\rangle \\\\ \\hline\n",
    "\\text{Multiply} & \\langle \\tilde{p}_1, \\tilde{r}_1 \\rangle \\oplus \\langle \\tilde{p}_2, \\tilde{r}_2 \\rangle & \\langle \\tilde{p}_1 \\tilde{p}_2, \\tilde{p_1} \\tilde{r}_2+\\tilde{r}_1 \\tilde{p}_2 \\rangle  \\\\ \\hline\n",
    "\\text{Left-divide} & \\langle \\tilde{p},\\tilde{r} \\rangle^{-1} & \\color{red}{\\text{FILL IN}} \\\\ \\hline\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "In general, a weight in the expectation semiring is a pair $\\langle \\tilde{p}, \\tilde{r} \\rangle$ that summarizes a set of paths (or partial paths, including edges in the base case):\n",
    "* $\\tilde{p}$ is the *unnormalized probability* of this set of paths (obtained by the `prob()` method)\n",
    "* $\\tilde{r} = \\tilde{p} \\bar{R} $ is the *unnormalized expected value* (obtained by the `value()` method)\n",
    "* $\\tilde{r}/\\tilde{p} = \\bar{R}$ is the *expected value* (obtained by the `expectation()` method)\n",
    "By taking the concatenation ($\\otimes$) of paths with edges and the union ($\\otimes$) of complete paths, we can build up the expected value of an entire FSA.  The key to doing this efficiently is that the distributive property holds, so that we can use dynamic programming to get the total weight $\\beta(\\text{initial state})$ of all paths in the FSA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "7323d9f8-97dc-4a11-876d-69a991ea21f3",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "from expectation_semiring import ExpectationSemiringWeight  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "7353ab80-0a20-4497-b1c2-33f8906ab07e",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def fsa_edge(char, prob, reward):\n",
    "    fsa = FST(ExpectationSemiringWeight, acceptor=True)\n",
    "    start = fsa.add_state()\n",
    "    end = fsa.add_state()\n",
    "    fsa.initial_state = start\n",
    "    fsa.set_final_weight(end)\n",
    "    fsa.add_arc(start, end, \n",
    "                input_label=char, output_label=char, \n",
    "                weight=ExpectationSemiringWeight(prob, prob*reward))\n",
    "    return fsa\n",
    "\n",
    "def show(fsa):\n",
    "    total = fsa.sum_paths()\n",
    "    print(f'total weight {total} ==> expected value {total.expectation()}')\n",
    "    display(fsa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "2b83ee30-c72e-4e16-b06f-3ed15fa82939",
    "deletable": false
   },
   "source": [
    "Let's check that $\\oplus$ works as expected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "a50b2712-bb9d-4483-98aa-5dc3a3adc992",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "a = fsa_edge('a',2,5)   # unnormalized probability of 2, reward of 5\n",
    "b = fsa_edge('b',3,10)  # unnormalized probability of 3, reward of 10\n",
    "show(a)\n",
    "show(b)\n",
    "show(a.union(b))        # 2/5 probability of getting reward 5, and 3/5 probability of getting reward 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "12924802-c12d-4da0-9d90-1254e9554b00",
    "deletable": false
   },
   "source": [
    "And let's check that $\\otimes$ works as expected.  To understand the $\\otimes$ computation, observe that in the second machine below, we have $\\tilde{p} = 2 \\cdot 3 \\cdot 2$ (multiplied along the arcs), while $\\tilde{r}$ is obtained in effect as $(2 \\cdot 5) \\cdot 3 \\cdot 2$ from the first arc, plus $2 \\cdot (3 \\cdot 10) \\cdot 2$ from the second arc, plus $2 \\cdot 3 \\cdot (2 \\cdot 5)$ from the third arc.  This rearranges into $\\tilde{r} = (2 \\cdot 3 \\cdot 2) \\cdot (5+10+5) = \\tilde{p} \\cdot (5+10+5)$, so $\\tilde{r}/\\tilde{p} = 5+10+5 = 20$ as desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "bb0ca83e-d800-4222-a7f6-329df8cf9fee",
    "scrolled": true,
    "deletable": false
   },
   "outputs": [],
   "source": [
    "ab  = a.concat(b);           show(ab)   # single path accepting 'ab'  with total reward of 5+10\n",
    "aba = a.concat(b).concat(a); show(aba)  # single path accepting 'aba' with total reward of 5+10+5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "4f0b2b98-9ce1-4b7d-baa6-4ea49d1e8e2f",
    "deletable": false
   },
   "source": [
    "<a name=\"ababa\"></a>Finally, let's try $\\oplus$ and $\\otimes$ together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "cba2d971-5ba7-4e9d-8b8c-7b2895cfa0d4",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "show(ab.union(aba))   # 6/18 chance of getting reward of 5+10, and 12/18 chance of getting reward of 5+10+5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "3a2845f6-1bd9-415a-a93d-ccb5f7ccf191",
    "deletable": false
   },
   "source": [
    "We should get the same answer if we apply semantics-preserving transformations to the FSA.  Such transformations may move the weights around or change the topology, but still associate the same weight with every path.  Let's try pushing first, so that the total expected cost of `'ab'` and of `'aba'` are pushed back to their initial arcs:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "f2cb5bf6-d728-4482-b5c1-2339f60156e3",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "show(ab.union(aba).push())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "9e8c3638-616e-474f-a5be-a22fd9735cd3",
    "deletable": false
   },
   "source": [
    "In the same spirit, we can find the minimal equivalent DFA, which in this case merges the common `'ab'` prefix.  Again we should get the same answer.  However, notice that this time we obtain the entire expected reward of `18.33` up front.  At state 2, we have 1/3 chance of stopping with `'ab'` and giving back `3.33` of the reward, and 2/3 chance of continuing on to `'aba'` and getting an additional `1.67` reward.  These effects cancel out.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "6d596ed2-0e46-49d4-a7c6-43e6df343b4b",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Minimization takes 3 successive OpenFST method calls, since minimization \n",
    "# requires a deterministic FSA, and determinization requires an epsilon-free FSA.  \n",
    "# Feel free to play around with these steps separately.\n",
    "show(ab.union(aba).remove_epsilon().determinize().minimize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "f382559a-5ee3-4281-b7b0-0b1454c76cab",
    "deletable": false
   },
   "source": [
    "It is possible to compute expectations under $p$ of any quantity, not just the expected reward (gain):\n",
    "* By defining $R(\\boldsymbol{y})$ values to be a loss rather than a reward, you can compute the expected loss (risk).  This is just a change of sign.\n",
    "* By defining $R(\\boldsymbol{y})$ to be a vector $(\\text{true_pos},\\text{true},\\text{pos})$ you can compute the expectation of that vector, $({\\mathbb E}[\\text{true_pos}],{\\mathbb E}[\\text{true}],{\\mathbb E}[\\text{pos}])$.  This is just computing three expectations at once.  Similarly, you could compute the expected rewards of several different plans.\n",
    "* By defining $R(\\boldsymbol{y})$ to be $\\boldsymbol{y}$'s feature vector or more generally the gradient of its score, $\\nabla G(\\boldsymbol{y})$, you can compute the expectation of that feature vector or gradient.  In this case, the path weight is $\\langle \\tilde{p}(\\boldsymbol{y}), \\tilde{p}(\\boldsymbol{y}) \\nabla G(\\boldsymbol{y}) \\rangle$.  \n",
    "\n",
    "Our implementation of `ExpectationSemiringWeight` therefore allows the second element to be a real number, a `numpy` array, a `ParamDict`, or pretty much any object that implements `+` and `*` operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "d000cbf4-adbc-4c48-a5e7-e771a6444de5",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "c = fsa_edge('c',2,np.array([1,2,3]))\n",
    "d = fsa_edge('d',5,np.array([4,5,6]))\n",
    "show(c.concat(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "fdeda472-0b37-482b-b6ed-1d759e2ec46d",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "c = fsa_edge('c',2,ParamDict(true=1,pos=2,true_pos=3))\n",
    "d = fsa_edge('d',5,ParamDict(true=4,pos=5,true_pos=6))\n",
    "show(c.concat(d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "b20cb466-1b72-42f3-af2a-a4a6a07da82e",
    "deletable": false
   },
   "source": [
    "#### Avoiding underflow/overflow\n",
    "\n",
    "Multiplying probabilities along a long path risks underflow, or overflow if they are unnormalized probabilities.  \n",
    "\n",
    "You already know the trick of switching from `RealSemiringWeight` to `LogSemiringWeight` (where $(\\oplus,\\otimes) = (\\text{logsumexp}, +)$).  But the logsumexp operation is a bit slow.  And in the case of expectation semirings, the $\\tilde{r}$ values may be as large or small as the $\\tilde{p}$ values, but can't be straightforwardly represented in the log domain because they may be negative.  \n",
    "\n",
    "Our `ExpectationSemiringWeight` class uses an alternative trick for avoiding underflow/overflow: it privately stores a scalar multiplier along with the $\\langle \\tilde{p},\\tilde{r} \\rangle$ pair.  This isn't unrelated to the log trick, since we actually store the *log* of the multiplier.  However, we ensure that this log is an integer, and we also store a multiplicand to account for the non-integer part and the sign.\n",
    "\n",
    "In effect, this builds on the standard floating-point representation, which already has the form (mantissa, exponent), where \"exponent\" is the integer log of a possibly large multiplier, and \"mantissa\" is a multiplicand that is close to 1 or -1.  We continue to use floating-point representations for $\\tilde{p}$ and $\\tilde{r}$; it's just that our (shared) log-multiplier effectively extends the range of the exponent beyond what's possible in a standard 64-bit float.  To understand this engineering trick, check out the comments at the top of [expectation_semiring.py](expectation_semiring.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "75ab7dbc-9f18-4a6c-bdcc-3737b600598b",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "w = ExpectationSemiringWeight(10,6)**50000   # enormous!\n",
    "w                                            # printed representation makes use of scientific notation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "12f2bf34-732d-4cec-92e5-c40cb54e9a8c",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "(w.prob(),          # far too large for a float\n",
    " w.value(),         # far too large for a float\n",
    " w.expectation(),   # but the ratio is manageable\n",
    " w.prob(log=True))  # and we are allowed to get the log(prob) to avoid overflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "6d8ef66a-4676-4364-be6d-7ac5ab98be58",
    "deletable": false
   },
   "source": [
    "Why is the expectation $\\approx 30000$?\n",
    "\n",
    "**Answer**: <span style='color:red'>FILL IN</span>\n",
    "\n",
    "Why is the log(prob) $\\approx 115129$?  (Note that the log is base $e$.)\n",
    "\n",
    "**Answer**: <span style='color:red'>FILL IN</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "987c2a1e-9062-41ea-bd8f-d1a5294f772c",
    "deletable": false
   },
   "source": [
    "#### Deeper discussion: The expectation semiring as a \"gradient semiring\"\n",
    "\n",
    "When discussing expected gradient vectors above, we characterized the weight of path $\\boldsymbol{y}$ as $\\langle \\tilde{p}(\\boldsymbol{y}), \\tilde{p}(\\boldsymbol{y}) \\nabla G(\\boldsymbol{y}) \\rangle$.  Observe that this can be interpreted as $\\langle \\tilde{p}(\\boldsymbol{y}), \\nabla \\tilde{p}(\\boldsymbol{y}) \\rangle$ (since $\\tilde{p} = \\exp G$ by definition).  \n",
    "\n",
    "This gives another interpretation of the expectation semiring as a simple device for tracking gradients.  A weight's first element is merely a real number with the usual operations from the real semiring, and its second element is always the gradient of the first element (with respect to some parameters).  It is easy to check that the semiring operations do preserve this property under addition, multiplication, and division of the weights.  The total weight of all paths must therefore be $\\langle Z, \\nabla Z \\rangle$, and dividing the second element by the first element indeed gives the expected score gradient, since $\\frac{\\nabla Z}{Z} = \\nabla \\log Z = \\mathbb{E}_{\\boldsymbol{y}\\sim p}[\\nabla G(\\boldsymbol{y})]$.  \n",
    "\n",
    "But why should tracking gradients also be useful in computing expected *rewards*?  Well, with a little trickery, you can regard expected rewards as an example of expected feature values, and thereby get them from $\\nabla \\log Z$.  Redefine $\\tilde{p}(\\boldsymbol{y}) = \\exp(G(\\boldsymbol{y}) + R(\\boldsymbol{y})\\cdot \\theta_{\\text{reward}})$ where $R(\\boldsymbol{y})$ is now used as a log-linear feature and $\\theta_{\\text{reward}}$ is its weight.  By setting $\\theta_{\\text{reward}}=0$, you can prevent the reward model from affecting the probability model at all.  Yet the partial derivative $\\partial \\log Z / \\partial \\theta_{\\text{reward}}$ is still the expected feature value \u2014 that is, the expected reward you want!  This is another way to see why our expected reward computation worked.\n",
    "\n",
    "But wait \u2014 if this is all about gradients, don't we have another way to compute gradients, namely automatic differentiation?  We do indeed.  In particular, you could just compute $Z$ in the real semiring (or the log semiring), but wrap each parameter as a PyTorch `Variable` (which mfst can handle by wrapping it further as `PythonValueSemiringWeight`).  Then `sum_paths` returns $Z$ as a `Variable`, and you could get $\\nabla \\log Z$ by backprop: `torch.log(Z).backward()`.  \n",
    "\n",
    "Our method below for computing training gradients by forward-backward in the expectation semiring is actually isomorphic to this method.  So why did we bother implementing it, when PyTorch backprop is a highly optimized version of the same computation?  Well, the expectation semiring is interesting to think about, and perhaps more intuitive in the case of expected rewards.  It also doesn't require building a computation graph in memory; that graph is implicit in the FSA itself.  But the main reason is that our Bayes rule decoder will rely on manipulating an FSA in the expectation semiring."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "e6c78743-8109-410a-ae6f-f2b0df5824d2",
    "deletable": false
   },
   "source": [
    "## Part 4 \u2014 Using FSTs to decode our CRF model\n",
    "\n",
    "To go beyond brute-force methods, we'll extend some of our homework 1 classes to specify FSTs (finite-state transducers).  This will give us access to the generic dynamic programming algorithms in OpenFST."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "596faa0f-b781-4198-91a6-acbf7888b07b",
    "deletable": false
   },
   "source": [
    "### FST task setting\n",
    "\n",
    "Here's the extended interface that we'll have to implement:\n",
    "<a name=\"TaskSetting\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "4c19b0ea-f6ed-444d-bab5-88b8f92e0fb6",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "class FstTaskSetting(TaskSetting):\n",
    "    \"\"\"\n",
    "    Extend homework 1's TaskSetting class with methods that return FSTs (rather than iterators)\n",
    "    to specify the relevant sets.  This permits efficient dynamic programming algorithms to\n",
    "    replace the brute-force algorithms.\n",
    "    \"\"\"\n",
    "            \n",
    "    def fsa_yy(self, *, xx, oo=None):\n",
    "        \"\"\"\n",
    "        As an alternative to `iterate_yy`, return an unweighted FSA in the BooleanSemiring\n",
    "        that defines the valid output sequences `yy` for input `xx`.  (Recall that in the  \n",
    "        OpenFST toolkit, an FSA is implemented as an \"acceptor\" FST where on each arc, the \n",
    "        input and output symbols are equal.)\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()\n",
    "         \n",
    "    def fsa_aa(self, *, xx):\n",
    "        \"\"\"\n",
    "        As an alternative to `iterate_aa`, return an unweighted FSA in the BooleanSemiring\n",
    "        that defines the valid plan sequences `aa` for input `xx`.\n",
    "        The default (as for `iterate_aa`) is to return just the valid output sequences.\n",
    "        \"\"\"\n",
    "        return self.fsa_yy(xx=xx)\n",
    "    \n",
    "    # We can get an iterator for free from the FSA, so to specify a particular task,\n",
    "    # it's enough to specify only the FSA and not the iterator.\n",
    "    def iterate_yy(self, *, xx, oo=None):\n",
    "        for path in self.fsa_yy(xx=xx, oo=oo).iterate_paths():\n",
    "            yield tuple(path.input_path)\n",
    "\n",
    "    def iterate_aa(self, *, xx):\n",
    "        for path in self.fsa_aa(xx=xx).iterate_paths():\n",
    "            yield tuple(path.input_path)\n",
    "    \n",
    "    def fst_reward(self, *, xx):\n",
    "        \"\"\"\n",
    "        As an alternative to `reward`, return an FST in the MaxPlusSemiring \n",
    "        that defines the reward function.   For every output string `yy` \n",
    "        and every plan `aa`, the FST should transduce `yy` to `aa` with weight R(a | x, y).\n",
    "        (Note that `yy` is the *input* to this FST.)\n",
    "        \n",
    "        This FST may accept illegal `yy` values since the probability model\n",
    "        will give them probability 0 anyway.  It may also produce illegal `aa`\n",
    "        values; it is up to the caller to compose it with `fst_aa`.  This allows\n",
    "        `fst_aa` to be overridden, and may also simplify the `fst_reward` machine.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    # In principle, we should here define generic implementations of the `TaskSetting` methods\n",
    "    # `iterate_yy`, `iterate_aa`, and `reward` that use the finite-state machines above.\n",
    "    # (These could still be overridden by simpler and faster direct implementations.)\n",
    "    # However, we can get away without these methods for purposes of this homework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "b1309542-ed7c-4f0d-a01e-e1ad0beea288",
    "deletable": false
   },
   "source": [
    "Now, your job is to extend `IobTask0` into an FST-enabled version.  \n",
    "This might be the trickiest part of the assignment.\n",
    "Here are some hints.\n",
    "\n",
    "For `fsa_yy`, you could build the FSA by specifying all its states and arcs explicitly.\n",
    "Or more elegantly, you could build the FSA from simpler machines using finite-state\n",
    "operations, as well as existing utility functions like `create_from_string` and \n",
    "`create_from_observable`.\n",
    "\n",
    "You have a similar choice with `fst_reward`.  However, it turns out to be remarkably \n",
    "tricky to define this machine in a declarative way, especially if you want to make\n",
    "it small (since the finite-state determinization and minimization constructions don't\n",
    "always apply).  Thus, we suggest constructing this machine by hand, to mimic a procedure \n",
    "where you read the `(yy,aa)` pair from left to right, adding a reward of `1` whenever\n",
    "you encounter a true positive and a reward of `-self.false_pos_penalty` whenever you\n",
    "encounter a false positive.  Our old `reward` function did something like this.\n",
    "\n",
    "You should be able to do this with just two states.  You enter the \"match\" state upon\n",
    "reading `B:B`.  Being in the \"match\" state means that `yy` and `aa` *started* proposing a chunk in \n",
    "the same place; they continue to match as long as you read `I:I`.  Depending on whether these two chunks also *end*\n",
    "in the same place, you may discover that they form a true positive, or a false positive \n",
    "and a false negative.  It is also possible to spot false positives and false negatives \n",
    "while in the \"nomatch\" state.  Make sure that you can read all possible symbol pairs \n",
    "(and also that you can stop) when in either state, and that you score these events correctly!\n",
    "The code can be made pretty concise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "3bc91d1d-6931-4b31-8d0d-0c06b7945721",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "class IobTask(IobTask0, FstTaskSetting):    \n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self._fsa_legal_yy = None  # cached machine that doesn't vary by call\n",
    "        self._fst_reward = None    # cached machine that doesn't vary by call (but it does vary by instance of the task, because of different false_pos_penalty values)\n",
    "    \n",
    "    def fsa_yy(self, *, xx, oo=None):\n",
    "        \"\"\"\n",
    "        An FSA in the BooleanSemiring that accepts just the legal IOB sequences for `xx` \u2014 \n",
    "        the ones that would be returned by `IobTask0.iterate_yy`.  Make sure to consider `oo`.\n",
    "        \"\"\"\n",
    "        # Hint: use `self.Y_alphabet`.\n",
    "        ### STUDENTS START\n",
    "        raise NotImplementedError()  # REPLACE ME\n",
    "        ### STUDENTS END\n",
    "                \n",
    "    def fst_reward(self, *, xx):\n",
    "        \"\"\"\n",
    "        An FST that can read *any* legal `yy`:`aa` pair, \n",
    "        and assign it the same weight that `IobTask0.reward` would have computed, \n",
    "        which depends on the number of true positives, the number of false positives,\n",
    "        and `self.false_pos_penalty`.\n",
    "        \"\"\"\n",
    "        # Since the reward for the IOB task does not happen to depend on xx,  \n",
    "        # we can reuse the reward FST from last time if we've already built it.\n",
    "        if self._fst_reward:\n",
    "            return self._fst_reward\n",
    "        \n",
    "        # Compute `self._fst_reward` before returning it.\n",
    "        # Make sure to use `MaxPlusSemiringWeight`.\n",
    "        ### STUDENTS START\n",
    "        raise NotImplementedError()  # REPLACE ME\n",
    "        ### STUDENTS END\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "25f414b2-2823-4622-91b6-ae18299e16f5",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "task = IobTask()\n",
    "fivewords = ('een','twee','drie','vier','vijf')   # a five-word Dutch \"sentence\" (= one, two, three, four, five)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "c6472f14-5c2c-45c0-8eeb-567ff2fb711f",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "task.fsa_yy(xx=fivewords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "a2790ae1-b5e7-4333-853a-f6708b7004ef",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "task.fsa_yy(xx=fivewords, oo='?O???')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "a65c7503-eed5-412d-8ea8-3d7e246408cf",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# confirm that fsa_yy describes the same set of strings as the original iterate_yy\n",
    "list(task.iterate_yy(xx=fivewords))\n",
    "assert (   set(task .iterate_yy(xx=fivewords))    # enumerates paths in fsa_yy\n",
    "        == set(task0.iterate_yy(xx=fivewords))  ) # hand-crafted iterator\n",
    "assert (   set(task .iterate_yy(xx=fivewords,oo='?O???')) \n",
    "        == set(task0.iterate_yy(xx=fivewords,oo='?O???')) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "6f5ec1e0-d1e6-452f-b6a3-300a83612574",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "fst_R = task.fst_reward(xx=fivewords) \n",
    "fst_R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "1713f5f1-1d77-4ec6-893b-994c1dcffdf0",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "list(task0.iterate_yy(xx=fivewords,oo='?O???'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "4b10d508-55ec-48bd-995b-fad948f3eec3",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "task0.reward(aa=('B', 'O', 'B', 'O', 'O'), yy=('B', 'O', 'B', 'O', 'O'), xx=fivewords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "606f84af-a7be-41e9-a9d4-a0a847a9daac",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# confirm that fst_R gives the same answer on ALL (yy,aa) pairs as the original reward() -- an extensive test!\n",
    "for yy in task.iterate_yy(xx=fivewords):\n",
    "    for aa in task.iterate_aa(xx=fivewords):\n",
    "        R = FST(''.join(yy)).compose(fst_R, FST(''.join(aa))).sum_paths()   # finite-state computation of R(aa | yy)\n",
    "        R0 = task.reward(aa=aa,xx=fivewords,yy=yy)               # old computation of R(aa | yy)\n",
    "        assert math.isclose(R,R0), f'fst reward={R}, true reward={R0}, F1_triple={task.reward_F1_triple(aa=aa,xx=fivewords,yy=yy)}, yy={yy}, aa={aa}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "532824d0-c917-417e-b343-f8fa102bf486",
    "deletable": false
   },
   "source": [
    "### FST probability model\n",
    "\n",
    "Given $\\boldsymbol{x}$, our CRF defines a trellis of possible $\\boldsymbol{y}$ values.  We will express this as a \n",
    "weighted FSA that maps each $\\boldsymbol{y}$ sequence to its unnormalized probability $\\tilde{p}(\\boldsymbol{y} \\mid \\boldsymbol{x}) = \\exp G(\\boldsymbol{x},\\boldsymbol{y})$.  \n",
    "\n",
    "So just as we earlier extended `TaskSetting` into `FstTaskSetting` with extra methods `fsa_yy` and `fst_reward`, we will now extend `BoltzmannModel` into `FstBoltzmannModel` with an extra method `fsa_uprob`.  \n",
    "\n",
    "We'll also override some of the `BoltzmannModel`'s existing methods with more efficient versions that make use of `fsa_uprob` with dynamic programming, instead of repeatedly calling `score` and `score_with_gradient`.  Fill in the missing methods below, based on work you've already done earlier in the notebook.  You should probably look back at `BoltzmannModel` from homework 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "b280c955-6aa5-460f-bbd6-43751f1128ff",
    "deletable": false
   },
   "source": [
    "Given $\\boldsymbol{x}$, our CRF defines a trellis of possible $\\boldsymbol{y}$ values.  We will express this as a \n",
    "weighted FSA that maps each $\\boldsymbol{y}$ sequence to its unnormalized probability $\\tilde{p}(\\boldsymbol{y} \\mid \\boldsymbol{x}) = \\exp G(\\boldsymbol{x},\\boldsymbol{y})$.\n",
    "\n",
    "So just as we earlier extended `TaskSetting` into `FstTaskSetting` with extra methods `fsa_yy` and `fst_reward`, we will now extend `BoltzmannModel` into `FstBoltzmannModel` with an extra method `fsa_uprob`.  We'll also override some of the `BoltzmannModel`'s existing methods with more efficient versions that make use of `fsa_uprob` with dynamic programming, instead of repeatedly calling the old `score` and `score_with_gradient` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "b3095c4a-2d96-4a94-8aa7-13de3d1223d1",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "class FstBoltzmannModel(BoltzmannModel):\n",
    "    \"\"\" \n",
    "    Extend homework 1's BoltzmannModel class with methods that can return a weighted FST \n",
    "    to score the yy values.  This permits efficient dynamic programming algorithms to\n",
    "    compute the normalizer and its gradient without brute-force enumeration of the yy values.\n",
    "    \"\"\"\n",
    "    \n",
    "    def fsa_uprob(self, *, xx, temperature=1, include_gradient=False):\n",
    "        \"\"\"\n",
    "        Given input `xx`, return a weighted FSA such that for any legal output `yy`,\n",
    "        the FSA accepts the sequence `yy` with `RealSemiringWeight` of\n",
    "        p\u0303(yy | xx) = exp G(xx,yy). (Note that this may overflow; we should\n",
    "        really have a flag saying to work in the log domain.)\n",
    "        \n",
    "        The FSA should not accept any `yy` outputs that are illegal according \n",
    "        to `self.task.fsa_yy(xx)`.\n",
    "        \n",
    "        If the include_gradient flag is set, then the weight should instead be\n",
    "        (p\u0303, \u2207p\u0303), which is an ExpectationSemiringWeight.  This version should not\n",
    "        overflow.  Note that the .expectation() method of this weight returns \n",
    "        \u2207p\u0303/p\u0303 = \u2207(log p\u0303) = \u2207G (which is the feature vector f(xx,yy) in the \n",
    "        log-linear case G=\u03b8\u22c5f).\n",
    "        \n",
    "        (What if `temperature != 1`?  It's not hard to see that the feature\n",
    "        vector should then be divided by the temperature throughout, including\n",
    "        in the gradient.)\n",
    "        \n",
    "        The FSA over `yy` values may be constructed on demand given `xx`.  However, \n",
    "        for some models, one might also be able to obtain the FSA by finite-state \n",
    "        composition, as `FST(xx).compose(crf).project(type='output')`, where `crf` \n",
    "        is a fixed static FST representing the entire CRF model.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def normalizer(self, *, xx, oo=None, temperature=1):\n",
    "        fsa = self.fsa_uprob(xx=xx, temperature=temperature)\n",
    "        if oo is not None:\n",
    "            fsa = fsa.compose(self.task.fsa_yy(xx=xx, oo=oo))\n",
    "        return fsa.sum_paths().value\n",
    "        \n",
    "    def logprob_gradient(self, *, xx, oo=None, yy=None):\n",
    "        # Compute the gradient of the clamped (numerator) term \n",
    "        # minus the gradient of the free (denominator) term\n",
    "        # to get p(yy | xx) or p(oo | xx).\n",
    "        # Hint: This is what the expectation semiring was *for*!\n",
    "        # Hint: Use `task.fsa_yy(xx=xx,oo=oo)` to restrict numerator to `oo`.\n",
    "        assert (oo is None) != (yy is None)\n",
    "        ### STUDENTS START\n",
    "        raise NotImplementedError()  # REPLACE ME\n",
    "        ### STUDENTS END\n",
    "\n",
    "    def sampler(self, *, xx, oo=None, temperature=1):\n",
    "        ### STUDENTS START\n",
    "        raise NotImplementedError()  # REPLACE ME\n",
    "        ### STUDENTS END\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "7525bf8b-46b2-4b11-b14e-e71c05644b9c",
    "deletable": false
   },
   "source": [
    "**Remark**: Recall that `score(xx,yy)` and `score_with_gradient(xx,yy)` are fast.  They do not have to build a whole `fsa_uprob(xx)` just to get the score of the `yy` path.  \n",
    "\n",
    "For this reason, we did not override them with FST versions, nor did we override `uprob`.  Recall that `uprob(yy)` just calls the fast exp(`score`).  (And `uprob(oo)` calls `normalizer`, which has already been overridden with an FST version.)  \n",
    "\n",
    "But as a matter of class design, does this mean that an implementor of `FstBoltzmannModel` is *still required to implement* `score` and `score_with_gradient`?  This seems annoying when they have already put the same information is in `fsa_uprob`.\n",
    "* Fortunately, there exist straightforward general implementations of `uprob`, `score`, and `score_with_gradient` in terms of `fsa_uprob`.  So these could be provided by a mix-in class.  \n",
    "* Or perhaps these old methods could simply be omitted since they won't be called.  The trainer and decision agent should normally bypass them in favor of methods like `logprob_gradient` that use the FST.  The main reason we have the old methods at all is to compare them to our new methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "2185e332-437c-462e-8001-0c0891e87757",
    "deletable": false
   },
   "source": [
    "Now extend `BigramCrfModel0` to support an FSA by defining `fsa_uprob`.  \n",
    "* The topology will look a lot like `build_HC_fsa`  from above, except that you should restrict it to tag sequences that are legal for the task at hand.  (This is specified by `task.fsa_yy` \u2014 as we mentioned before, `BigramCrfModel` is a *general* tagger that could be used for tasks other than IOB tagging!)\n",
    "* The arc weights will be computed as in `BigramCrfModel0.score_with_gradient`.  That is, instead of using fixed parameters `same_weight` and `change_weight`, each arc and each final state will have a positive real weight $\\psi$, which is determined by about 3 features whose weights live in `params`.  If you are including the gradient, the weight should be $\\langle \\psi, \\nabla \\psi \\rangle$, where $\\nabla \\psi$ is $\\psi$ times that (very sparse) feature vector.  It will be convenient to build that feature vector in any case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "8f58b7cb-b32e-4fd9-b47f-5a7e3ef17ea7",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "class BigramCrfModel(BigramCrfModel0, FstBoltzmannModel):  \n",
    "    \n",
    "    def fsa_uprob(self, *, xx, temperature=1, include_gradient=False):\n",
    "        \n",
    "        def weight(features):\n",
    "            \"\"\"\n",
    "            Convert a feature vector to a weight in the appropriate semiring, \n",
    "            using `self.params` and `temperature`.\n",
    "            \"\"\"\n",
    "            ### STUDENTS START\n",
    "            raise NotImplementedError()  # REPLACE ME\n",
    "            ### STUDENTS END\n",
    "        \n",
    "        fsa = FST(ExpectationSemiringWeight if include_gradient else RealSemiringWeight, \n",
    "                  acceptor=True)\n",
    "        ### STUDENTS START\n",
    "        raise NotImplementedError()  # REPLACE ME\n",
    "        ### STUDENTS END\n",
    "        return fsa.intersect(self.task.fsa_yy(xx=xx))   # restrict to taggings that are legal for `task`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "34b1cb76-bad3-4834-9126-827842101add",
    "deletable": false
   },
   "source": [
    "Now we can create `model` that is just like `model0` but has the extra FST methods.  Since we already trained `model0`, we'll just steal a copy of its parameters (for now) rather than retraining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "311065ba-5156-43ea-8632-b41563363a60",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "class TrainableBigramCrfModel(L2LogLikelihood, BigramCrfModel): \n",
    "    pass   # inherit everything from the two parents\n",
    "\n",
    "model = TrainableBigramCrfModel(task, \n",
    "                                vocab=vocab_small, \n",
    "                                regularization_coeff=15,\n",
    "                                num_examples=len(data_small))\n",
    "model.params = model0.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "36b1f962-679e-475f-90fd-11fe7cd35376",
    "deletable": false
   },
   "source": [
    "To check our FSA and finite-state methods, let's first make sure that `fsa_uprob` and `normalizer` are getting the same probabilities and feature vectors on short dev sentences that we got with the simple `uprob` and `normalizer` methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "024f6f7c-a96f-4112-bf83-c9d16ad03bbe",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def compare_models(model,model0,dataset):   # model is an FstModel, but model0 uses the old homework 1 methods\n",
    "\n",
    "    for xx,oo,yy in iterate_data(dataset):\n",
    "        fsa     = model.fsa_uprob(xx=xx)\n",
    "        fsagrad = model.fsa_uprob(xx=xx, include_gradient=True)\n",
    "        # display(fsa)   # uncomment for debugging\n",
    "    \n",
    "        uprob    = fsa    .compose(FST(yy)).sum_paths().value          # weight of yy in the FSA\n",
    "        gradient = fsagrad.compose(FST(yy)).sum_paths().expectation()  # feature vector for computing that weight\n",
    "\n",
    "        uprob0      = model0.uprob(xx=xx, yy=yy)                  \n",
    "        _,gradient0 = model0.score_with_gradient(xx=xx, yy=yy)    \n",
    "        assert math.isclose(uprob, uprob0), f'p\u0303(yy | xx) = {uprob} (new), {uprob0} (old)\\n\\t{gradient}\\n\\t{gradient0},\\n\\t{gradient - gradient0}'\n",
    "    \n",
    "        if oo:\n",
    "            uprob  = model.normalizer(xx=xx, oo=oo)\n",
    "            uprob0 = model0.normalizer(xx=xx, oo=oo)\n",
    "            assert math.isclose(uprob, uprob0), f'p\u0303(oo | xx) = {uprob} (new), {uprob0} (old)'\n",
    "    \n",
    "        Z = model.normalizer(xx=xx)\n",
    "        Z0 = model0.normalizer(xx=xx)   # the brute-force method that we overrode\n",
    "        assert math.isclose(Z,Z0), f'Z(xx) = {Z} (new), {Z0} (old)'\n",
    "        \n",
    "compare_models(model, model0, 'dev-small')   # asserts that models match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "5789267b-5d64-4b08-acda-c9b1459dbf69",
    "deletable": false
   },
   "source": [
    "Once it works, let's try training with the new model!  \n",
    "(Is it faster than before?  Probably not, because these sentences are still too short for the FSA to beat brute-force.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "666073e2-9c10-4691-8b8f-c53a85d5b964",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "sgd_trainer = SGDTrainer(epochs=10)\n",
    "%time sgd_trainer.train(model, data_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "5cde659c-cc0e-4587-b7a7-d22b4bb8007e",
    "deletable": false
   },
   "source": [
    "Hopefully you learned exactly the same params as before.  You could check by comparing `model.params` with `model0.params`, but let's just compare the predictions of the parameters, exactly as we did before retraining `model.params` with the new algorithms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "47224b2d-e16d-4d0e-858c-493d306432d5",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "compare_models(model, model0, 'dev-small')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "2022bd90-0562-4be7-a840-e891f5a24f0c",
    "deletable": false
   },
   "source": [
    "Oh, and let's compare the results of sampling ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "d1ea2179-80cf-4992-9b0c-74b8c556fe7b",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def samples(model,xx,oo=None,n=1000):\n",
    "    sampler = model.sampler(xx=xx,oo=oo)   # exact sampler\n",
    "    counts = ParamDict()             # not actually using this for params\n",
    "    for yy in islice(sampler,n):\n",
    "        counts[''.join(yy)] += 1\n",
    "    return counts\n",
    "\n",
    "xx = ('brussel', '/', 'den', 'haag')   # a dev sentence whose correct tagging is BOBI\n",
    "n = 100000\n",
    "%time s  = samples(model,  xx, n=n)\n",
    "%time s0 = samples(model0, xx, n=n)\n",
    "(s-s0)/n     # difference in estimated probabilities: hopefully small (could do hypothesis testing!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "77076007-5637-4fe7-9ad6-957747c0f86b",
    "deletable": false
   },
   "source": [
    "Just to prove that the finite-state method really was worth implementing for speed, let's try a longer sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "2c79d40f-d812-4287-958c-a2af1fabfa96",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "xx = xx * 3    # 12-word sentence\n",
    "n = 10\n",
    "%time s  = samples(model,  xx, n=n)\n",
    "%time s0 = samples(model0, xx, n=n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "6d449fcf-c8bd-4c96-aefa-d7f967b0369a",
    "deletable": false
   },
   "source": [
    "Linear-time really does beat exponential-time, especially on longer sentences.  Even one long sentence in the corpus would greatly slow down the brute-force algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "fc6ccc9f-a343-4bef-b93f-274081ee46f1",
    "deletable": false
   },
   "source": [
    "### Forward-backward for training\n",
    "\n",
    "You've been using the forward algorithm (`sum_paths`) to compute the total weight of `fsa_uprob`.  When the FSA is weighted by the expectation semiring, this is rather slow.  The reason is that every $\\oplus$ operation involves a vector sum, and every $\\otimes$ operation involves a linear combination of vectors.   \n",
    "\n",
    "Moreover, these are unfortunately *dense* vector operations.  Basically, you are sweeping from left to right through the FSA, adding up the features on the arcs as you encounter them.  For a state $s$ at time step $i$, the forward weight $\\alpha(s)$ includes a vector that is dense with all features encountered on all the length-$i$ paths to that state.  \n",
    "\n",
    "Remember, however, that the forward-backward algorithm is another way to compute expectations and gradients.  It turns out that `sum_paths` for machines in the expectation semiring can be computed faster by the forward-backward algorithm.  Here, instead of pushing feature vectors from the initial state to the final state, the feature vectors stay where they are, and we push scalar probabilities toward them from both sides to determine how heavily to weight them in the final sum.\n",
    "\n",
    "Both algorithms have the same asymptotic runtime, in the sense that on a machine with $m$ arcs, they both perform $O(m)$ multiply-adds, in the sense of multiplying a vector by a scalar and adding it to a total.  However, these vectors tend to be dense in the forward algorithm \u2014 in the forward-backward algorithm they are just the feature vectors attached to individual arcs, which are usually quite sparse.\n",
    "\n",
    "#### The algorithm\n",
    "\n",
    "Specifically, suppose each arc $e$ in the machine is labeled with an expectation semiring weight $\\langle \\psi_e, \\boldsymbol{v}_e \\rangle$, and its source and destination states are $s_e$ and $t_e$.  Each final state $f$ has a final weight of $\\langle \\psi_f, \\boldsymbol{v}_f \\rangle$.  \n",
    "\n",
    "Temporarily ignore the $\\boldsymbol{v}_e$ part of each weight so that our machine appears to be in the real semiring.  Run forward-backward over that simpler machine to obtain the forward probabilities $\\alpha(s)$, the backward probabilities $\\beta(t)$, and the sum of paths $Z = \\beta(\\text{initial state})$.  \n",
    "\n",
    "Now the total weight of all paths in the original machine is $$\\langle Z, \\sum_e \\alpha(s_e) \\cdot \\boldsymbol{v}_e \\cdot \\beta(t_e) \\rangle + \\sum_f \\alpha(f) \\boldsymbol{v}_f$$\n",
    "where the second term is simply a weighted sum of the (sparse) feature vectors on the edges.  This is really just the standard way of collecting expected counts during the forward-backward algorithm.  (You might have expected to see a factor of $\\psi_e$ in the sum, but $\\boldsymbol{v}_e$ has already been weighted by $\\psi_e$.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "2cf6b125-9490-4c3e-8b89-629a6ccdfbb4",
    "deletable": false
   },
   "source": [
    "#### Deeper discussion\n",
    "\n",
    "It turns out that the forward algorithm is a special case of *forward-mode automatic differentiation*, which computes the objective function $F(\\boldsymbol{\\theta})$ and its gradient in parallel using a single forward pass through the computation graph.  As you know from our previous discussion of the expectation semiring, it replaces each node $x$ in the computation graph with a pair $\\langle x, \\nabla_{\\boldsymbol{\\theta}} x \\rangle$, so that at the end, it has found $\\langle F, \\nabla_{\\boldsymbol{\\theta}} x \\rangle$.  The trouble is that each $\\nabla_{\\boldsymbol{\\theta}} x$ is an entire vector in $\\mathbb{R}^K$ (all values $\\partial x / \\partial \\theta_k$),where $K$ is the number of parameters.\n",
    "\n",
    "By contrast, the forward-backward algorithm is a special case of *reverse-mode automatic differentiation*, which uses both a forward pass to compute $F$ and a backward pass to compute its gradient.  The backward pass augments each node $x$ with an adjoint, which is just a scalar ($\\partial F / \\partial x$) provided that $F(\\boldsymbol{\\theta})$ is a scalar.  \n",
    "\n",
    "In short, for a function $F: \\mathbb{R}^K \\rightarrow \\mathbb{R}$, reverse-mode is much better.  (Forward-mode does win for a function $\\mathbb{R}^K \\rightarrow \\mathbb{R}^{K'}$ where $K' \\geq K$, which is actually the case when we are computing expected reward.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "b9bfaa54-c8b9-4e17-b3df-33e6f9066456",
    "deletable": false
   },
   "source": [
    "#### Implementing forward-backward\n",
    "\n",
    "Let's try it out using our 12-word sentence from above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "0366757b-bc5c-4193-af01-7bf6e79f8138",
    "scrolled": true,
    "deletable": false
   },
   "outputs": [],
   "source": [
    "fsa = model.fsa_uprob(xx=xx, include_gradient=True)\n",
    "ZZ = fsa.sum_paths()\n",
    "ZZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "e26d549e-7fe6-4ba5-b1c6-7fbb579867a1",
    "deletable": false
   },
   "source": [
    "Here's how we can move our FSA into the real semiring so that we can run ordinary fast forward-backward on it.  The `lift()` method makes a copy of the FSA but maps the weights into a new semiring using a user-provided function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "c26b46e6-9fad-4467-aac2-333c3c05d397",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "fsa_real = fsa.lift(RealSemiringWeight, lambda w: w.prob())\n",
    "fsa_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "63c11cca-2f67-4493-b29d-5035779f5f7d",
    "scrolled": true,
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# OpenFST uses the term \"shortest distance\" to mean the semiring generalization of shortest\n",
    "# distance, namely the total probability of all prefix paths to a state or suffix paths from a state.\n",
    "alpha = fsa_real.shortest_distance() \n",
    "beta = fsa_real.shortest_distance(reverse=True)\n",
    "Z = beta[fsa_real.initial_state]\n",
    "for s in fsa_real.states:\n",
    "    print(s, alpha[s]*beta[s] / Z, alpha[s], beta[s])  # marginal probabilities of being in different states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "c1ed6682-a929-44c5-9123-959830102a89",
    "deletable": false
   },
   "source": [
    "To avoid numerical issues during forward-backward, it's better to lift the weight $\\langle \\psi,\\boldsymbol{v}\\rangle$ not into the real semiring as $\\psi$, but into the log semiring as $\\log \\psi$.  \n",
    "Or we can lift it into the expectation semiring as $\\langle \\psi,0 \\rangle$, since such a weight behaves like $\\psi \\in \\mathbb{R}$, and won't overflow/underflow thanks to our cool implementation.  \n",
    "We'll do the latter, using a special `dropvalue` method that maps $\\langle \\psi,\\boldsymbol{v}\\rangle \\mapsto \\langle \\psi,0\\rangle$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "c192507b-d732-4af6-adcc-9c676ef8fb10",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def sum_paths_fb(fst):\n",
    "    \"Use forward-backward to find the pathsum of an FST in the expectation semiring.\" \n",
    "    assert fst.semiring is ExpectationSemiringWeight\n",
    "    fst_real = fst.lift(ExpectationSemiringWeight, converter=lambda w: w.dropvalue())\n",
    "    alpha = fst_real.shortest_distance() \n",
    "    beta  = fst_real.shortest_distance(reverse=True)\n",
    "    Z = beta[fst_real.initial_state]\n",
    "\n",
    "    total = ExpectationSemiringWeight(0)\n",
    "    for s in fst.states:\n",
    "        # if s is final, then get_arcs will yield an arc to state -1 with the final-state weight\n",
    "        for e in fst.get_arcs(s):\n",
    "            multiplier = alpha[s] * (beta[e.nextstate] if e.nextstate >= 0 else ExpectationSemiringWeight.one)\n",
    "            total += multiplier * e.weight     # avoid multiplying the big `e.weight` by alpha and beta separately \n",
    "    # The second element of total will now be correct, but we need to replace the first element with Z.\n",
    "    # Here's a slightly hacky approach that remains safe (even if total and Z are encoded with different multipliers).\n",
    "    return total + (Z.dropvalue() - total.dropvalue())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "9d62a2a9-aba9-4056-aef0-5e5ada01b5e3",
    "deletable": false
   },
   "source": [
    "Let's confirm that it works.  You may also want to play around with the [machines from the expectation semiring section](#ababa) to get a better intuition for why it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "6ef0946a-472b-4003-8121-41e1a8d25a6a",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "assert sum_paths_fb(fsa).approx_eq(ZZ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "618947d9-306a-474b-a9f2-78456f0a8173",
    "deletable": false
   },
   "source": [
    "**Implementation:** To activate this special handling, we'll simply patch `FST.sum_paths` to notice when the FST is in the expectation semiring, and use the faster algorithm then."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "db5d7f31-4869-48bd-bab0-2a67476f2071",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "FST.expectation_uses_fb = True       # control whether we use the fast method\n",
    "\n",
    "def sum_paths_with_fb(self, *args, **kwargs):\n",
    "    if FST.expectation_uses_fb and self.semiring is ExpectationSemiringWeight:\n",
    "        return sum_paths_fb(self, *args, **kwargs)\n",
    "    else:\n",
    "        return self._sum_paths(*args, **kwargs)\n",
    "    \n",
    "if not hasattr(FST,'_sum_paths'):\n",
    "    FST._sum_paths = FST.sum_paths   # save the original method\n",
    "FST.sum_paths = sum_paths_with_fb    # replace the method dynamically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "400fb30f-899a-402d-9cca-17a32b4420b4",
    "deletable": false
   },
   "source": [
    "Let's try training again, this time using forward-backward.  Again, for these tiny sentences, the speedup won't be apparent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "50b5e694-6081-4c18-a02c-3033d220bcb7",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "sgd_trainer = SGDTrainer(epochs=10)\n",
    "%time sgd_trainer.train(model, data_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "40416d62-ca03-4ca1-8ba4-5217f54267e6",
    "deletable": false
   },
   "source": [
    "But how about the full dataset?  We'll have to replace our `model` with one that has a larger vocabulary and hence a larger feature set.  Adapting a bit of code from before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "4a0f6f34-0306-4fae-9555-5d5cbfcb7422",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "data_large = list(iterate_data('train'))\n",
    "vocab_large = vocab_from_data(data_large)\n",
    "(len(vocab_large), list(islice(vocab_large,10)))  # size of vocab and 10 words from it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "72456a50-60da-4d40-9219-b41199c545bb",
    "deletable": false
   },
   "source": [
    "Let's compare the speed of the forward strategy versus forward-backward.  The model has about 30000 features, most of which are not used on any given sentence.  So if you use a dense vector class such as `numpy.array`, you will be spending a lot of time rapidly adding multiples of zero together.  Instead a sparse vector class such as `ParamDict` should save some time.  And once you're using such a sparse vector class, the forward-backward strategy should help (especially on longer sentences)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "da0839d2-bae1-4653-a830-3c02ac9d1e87",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "FST.expectation_uses_fb = False\n",
    "\n",
    "model = TrainableBigramCrfModel(task, \n",
    "                                vocab=vocab_large, \n",
    "                                regularization_coeff=15,\n",
    "                                num_examples=len(data_large))\n",
    "sgd_trainer = SGDTrainer(epochs=1)\n",
    "%time sgd_trainer.train(model, data_large[0:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "8badfc8f-e8de-4232-a26f-c7ea2c1610dc",
    "scrolled": true,
    "deletable": false
   },
   "outputs": [],
   "source": [
    "FST.expectation_uses_fb = True\n",
    "\n",
    "model = TrainableBigramCrfModel(task, \n",
    "                                vocab=vocab_large, \n",
    "                                regularization_coeff=15,    # you could play with the regularizer\n",
    "                                num_examples=len(data_large))\n",
    "sgd_trainer = SGDTrainer(epochs=1)\n",
    "%time sgd_trainer.train(model, data_large[0:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "717647e1-6b78-4382-a9f9-4426837a3715",
    "deletable": false
   },
   "source": [
    "Ok, let's train a real model that we will use for the rest of the homework.  Go get something to eat because this could take an hour ... but you should only have to do it once.  (Once for now, anyway.  You might want to tune it some more at the end of the notebook, before running your final test.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "97ae5181-1176-4ae6-83f3-76127f73a852",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "sgd_trainer = SGDTrainer(epochs=5)           # constant stepsize; you could play with the stepsize and its decay rate\n",
    "%time sgd_trainer.train(model, data_large)   # keep on training current model (the trainer will shuffle the dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "524d8d53-e63b-45ea-a99f-cb16b9958f99",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "len(model.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "8bc3bc53-9b2a-4f57-809c-4dc4b3619930",
    "deletable": false
   },
   "source": [
    "### FST Viterbi decision agent\n",
    "\n",
    "Now that we've trained our model, a natural thing to do is to see how well a simple Viterbi decision agent can fare.  However, it will be rather slow on these full-length sentences!  Let's try just the *very first* dev sentence ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "a74235e5-0028-4bc1-bcda-1da96081c9a8",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "agent1 = ViterbiAgent(task, model)\n",
    "%time agent1.test_F1(islice(iterate_data('dev'),1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "129a1d15-0ab9-43d6-ab2e-4f79566ace60",
    "deletable": false
   },
   "source": [
    "Hmm, you probably had to interrupt the notebook kernel on that one.  (It's a 24-word sentence with only 3 observed tags, so brute force isn't going to terminate any time soon.)  \n",
    "\n",
    "But you could try evaluating the same agent on 'dev-small'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "0fe200c0-5cd8-4db1-b98a-2e7a80f5b86a",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "agent1 = ViterbiAgent(task, model)\n",
    "agent1.test_F1(iterate_data('dev-small'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "cd68abaa-065b-4115-acf1-0bef22fc803f",
    "deletable": false
   },
   "source": [
    "Unfortunately, we do even worse here than our earlier `agent0` with `model0`.  That's because `'dev-small'` is not the kind of data that `model` was trained to work on \u2014 a case of \"domain mismatch.\"  (In particular, notice that `model` has learned to predict relatively few chunks ... far too few for `'dev-small'`.  As a result, it gets very low recall.  It also gets lower precision than `model0`.)\n",
    "\n",
    "We'd better figure out how to test on our actual data domain.  Let's extend our agent to use FSTs, just as we extended our task setting and our model!  You have enough tools to fill this in.  \n",
    "\n",
    "Properly speaking, your `FstViterbiAgent` will find the *path* of highest model probability (given `xx`,`oo`) and report its string `yy`.  This is the traditional Viterbi decoding strategy.  Why might it not necessarily find the highest-probability *string*?  What could you do to fix that (and how expensive would it be)?  Will it find the highest-probability string when it's applied to `FstBigramCrfModel`?  Why or why not?\n",
    "\n",
    "**Answer**: <span style='color:red'>FILL IN</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "fa1b3581-8331-4827-bcb3-096653ae69f0",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "class FstViterbiAgent(ViterbiAgent):\n",
    "\n",
    "    def decision(self, *, xx, oo=None):\n",
    "        # Hint: Start with `fsa_uprob` and `lift` it into the tropical semiring to avoid underflow\n",
    "        # Hint: You're trying to choose the `yy` with highest posterior probability since you are \n",
    "        #        a Viterbi agent; info about which `yy` are compatible with `oo` is given by the \n",
    "        #        task setting, not the model.\n",
    "        ### STUDENTS START\n",
    "        raise NotImplementedError()  # REPLACE ME\n",
    "        ### STUDENTS END\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "2be18920-caf3-4b1a-9090-88db0079a1b0",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "agent = FstViterbiAgent(task, model)\n",
    "agent.test_F1(iterate_data('dev-small'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "2a73211e-666b-4fb0-b6ff-efbbc28045cb",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "for xx,oo,yy in iterate_data('dev-small'):\n",
    "    yy = agent.decision(xx=xx,oo=oo)     # FST\n",
    "    yy1 = agent1.decision(xx=xx,oo=oo)   # brute-force\n",
    "    assert yy == yy1, f'yy = {yy}, yy1 = {yy1}, oo = {oo}, xx = {xx}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "90a3a375-1cbc-47d8-b965-444230239eeb",
    "deletable": false
   },
   "source": [
    "If you got the same answers as before on `'dev-small'`, now try it on `dev`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "fddb6995-8516-47ec-98bd-f4b2c0497584",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "%time agent.test_F1(iterate_data('dev'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "556fda8b-3850-49c5-9c75-b57603c11e4f",
    "deletable": false
   },
   "source": [
    "Well, that's a lot faster, but the recall on the 1-best path is still way too low.  Since `pos` is only 15, this implies that the single best path rarely has any chunks.  On at least 185 of the 200 dev sentences, the best path was just `OOOO...`.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "c94526e1-62d8-4677-b9a3-731e4e2beee0",
    "deletable": false
   },
   "source": [
    "### FST Bayes rule agent\n",
    "\n",
    "A smarter agent would realize that the low recall is killing the F1 score.  To get F1 score up, it had better take a risk and predict some entities.  The safest entities to guess would be those with a high *marginal* probability, which means summing over paths.\n",
    "\n",
    "This is what a Bayes rule will do.  As we saw in homework 1, it will try to maximize our expected reward, or at least our expected [proxy reward](#proxy).  \n",
    "\n",
    "The brute-force Bayes agent from homework 1 looped over the exponentially large set of `(aa,yy)` pairs to compute the Bayes decision $$ \\text{argmax}_a \\mathbb{E}_{y\\sim p(\\cdot | x)}[R(a | x, y)] $$\n",
    "But here's a sketch of a much faster algorithm for computing the optimal chunking under our particular proxy reward function, given our particular model:\n",
    "\n",
    "* Observe that in a sentence of length $J$, we have $O(J^2)$ possible chunks.  In principle, we can find the marginal probability of each of chunk.  For example, what is the marginal probability of a length-5 chunk starting at word 12?  Such a chunk corresponds to a `BIIII` substring that starts at word 12 and is not immediately followed by another `I`.  It's not too hard to see how to find the total weight of all such paths, with the help of pre-computed $\\alpha(s)$ and $\\beta(t)$ quantities to sum over the parts before and after `BIIII`.  A first guess is that it takes $O(J)$ time to score each of the $O(J^2)$ chunks, but maybe you can see how to do it in $O(J^2)$ time altogether.\n",
    "* If the marginal probability of a chunk is $p$, then the expected reward of including the chunk is $p \\cdot 1 + (1-p) \\cdot (-\\lambda)$.  We would prefer to include the chunk if this is positive, i.e., if $p \\geq \\frac{\\lambda}{1+\\lambda} \\in (0,1)$.  (This fits with the idea that low $\\lambda$ induces us to predict more chunks.)\n",
    "* However, overlapping chunks are not allowed.  Thus, we must select a subset of non-overlapping chunks with the maximum *total* expected reward.  This is itself a dynamic programming problem.  (We might prefer to omit the most probable chunk if that would let us take two or more slightly less probable chunks.)  Maybe you can see how to handle this DP problem as finding the highest-weighted path in a certain acyclic graph, i.e., a problem in the $(\\max,+)$ semiring.  The graph has $O(J^2)$ edges \u2014 one per chunk \u2014 and thus this stage of the algorithm also takes $O(J^2)$.\n",
    "\n",
    "Moreover, we don't need to implement this algorithm from scratch or even design it!  The algorithm will pretty much fall out of a finite-state recipe, cooked with FSTs that are already in our pantry."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "e28923af-4994-4ab0-9561-b65383a4a669",
    "deletable": false
   },
   "source": [
    "#### Exploring an example\n",
    "\n",
    "Let's illustrate with a small example.  It has 1 true chunk, `radio roxy`, but the Viterbi path has 0 chunks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "f4ade1d9-61d5-4107-8ad8-db1b5e6eff25",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "xx,oo,yy = list(iterate_data('dev'))[25]\n",
    "xx    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "61fdeddf-1678-47c7-80f4-3cdfc7f0d701",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "model.fsa_uprob(xx=xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "e519bb25-70d2-46e1-9863-f3aa382865a9",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "yy_hat = agent.decision(xx=xx)\n",
    "yy_hat, model.prob(xx=xx, yy=yy_hat)    # Viterbi decision and its probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "20abffe5-021e-4643-aeb0-fdeeda4479cf",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "yy, model.prob(xx=xx, yy=yy)            # true yy and its probability "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "75b77e46-0d99-4301-ae00-628a1646b6b9",
    "deletable": false
   },
   "source": [
    "The basic idea is to construct a single FSA in the (max,+) semiring that scores the different $\\boldsymbol{a}$ sequences according to their expected rewards.  \n",
    "\n",
    "We start with an FST that assigns to each $\\boldsymbol{y}:\\boldsymbol{a}$ pair the weight $\\langle \\tilde{p}, \\tilde{p}r \\rangle$ in the expectation semiring, where \n",
    "* $\\tilde{p} = \\tilde{p}(\\boldsymbol{y} \\mid \\boldsymbol{x})$ or $\\tilde{p} = \\tilde{p}(\\boldsymbol{y} \\mid \\boldsymbol{x},\\boldsymbol{o})$\n",
    "* $r = R(\\boldsymbol{a} \\mid \\boldsymbol{x},\\boldsymbol{y})$\n",
    "\n",
    "To construct this FST, we just have to lift `fsa_uprob` from the $(+,\\times)$ semiring to the expectation semiring (via $\\tilde{p} \\mapsto \\langle \\tilde{p}, 0 \\rangle$) and lift `fst_reward` from the $(\\max,+)$ semiring to the expectation semiring (via $r \\mapsto \\langle 1,r \\rangle$)\n",
    "\n",
    "Then composing these lifted machines in the expectation semiring will combine an `fsa_uprob` path that accepts $\\boldsymbol{y}$ with probability $\\tilde{p}$ with an `fst_reward` path that transduces $\\boldsymbol{y}$ to $\\boldsymbol{a}$ with reward $r$.   For the weight of this combined path, it multiplies the lifted versions of these weights to yield $\\langle \\tilde{p}, 0 \\rangle \\otimes \\langle 1, r \\rangle = \\langle \\tilde{p}, \\tilde{p}r \\rangle$ as desired.  \n",
    "\n",
    "This happens for each $\\boldsymbol{y}:\\boldsymbol{a}$ pair, but structure is shared among pairs in the usual way, so the resulting FST is compact.  Note that `fsa_uprob` has $\\leq 3J$ states and `fst_reward` has $2$ states, so the composed machine will have $\\leq 6J$ states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "b060fd51-19ce-4fb0-abbd-816e03aa8d02",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "fsa_uprob_lifted =  model.fsa_uprob(xx=xx)       \\\n",
    "                    .lift(ExpectationSemiringWeight, lambda p: ExpectationSemiringWeight(p.value,0))\n",
    "fst_reward_lifted = task.fst_reward(xx=xx)       \\\n",
    "                    .lift(ExpectationSemiringWeight, lambda r: ExpectationSemiringWeight(1,r.value))\n",
    "fst_both = fsa_uprob_lifted.compose(fst_reward_lifted)\n",
    "\n",
    "print(fsa_uprob_lifted.num_states, fst_reward_lifted.num_states, fst_both.num_states)\n",
    "fst_both"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "9c27fd68-272f-4b0b-9761-fc281ace954e",
    "deletable": false
   },
   "source": [
    "#### Evaluating plans\n",
    "\n",
    "We would now like to marginalize over the $\\boldsymbol{y}$ values, so that the machine will accept each $\\boldsymbol{a}$ with its expected reward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "e2a5238b-bc78-476d-9dfc-057ddbd5ab14",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "fsa_reward = fst_both.project('output')   # drop the input (yy) labels, \n",
    "                                          # leaving the output (aa) labels and weights unchanged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "65588fbd-65cc-4729-a34b-a12ca75433b2",
    "deletable": false
   },
   "source": [
    "Let's look at the expected rewards of a couple of selected plans `aa` -- the optimal plan and the Viterbi plan:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "ba050073-f23d-43d2-9664-0e2259947c48",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "aa_star = yy                # the optimal plan is the true tagging (which we can't know without peeking)\n",
    "aa_top  = yy_hat            # the Viterbi plan is the most probable tagging (computed before)\n",
    "\n",
    "def expected_reward(aa, trace=False):\n",
    "    total = fsa_reward.compose(FST(aa)).sum_paths() \n",
    "    expectation = total.expectation()\n",
    "    if trace:\n",
    "        print(f'paths with aa={aa} ==> total weight {total} ==> expected reward {expectation}')\n",
    "    return expectation\n",
    "    \n",
    "expected_reward(aa_star, trace=True)\n",
    "expected_reward(aa_top, trace=True)\n",
    "print(f'Z = {fsa_uprob_lifted.sum_paths()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "703d207d-d14c-4dd3-afdd-2ccb7b7752d1",
    "deletable": false
   },
   "source": [
    "Regardless of `aa`, the total unnormalized probability of the many paths mapping the various `yy` to `aa` is the same.  It is just $Z$, the total unnormalized probability of `yy` values, which is *unchanged by the choice of `aa`*.  (That is because our decision agent's action sequence `aa` does not affect which chunks `yy` the environment has actually placed there -- in contrast to a reinforcement learning agent, whose actions can affect the environment.)\n",
    "\n",
    "However, each `aa` has different expected reward, obtained by summing over those various `yy` paths.  As shown above, this is computed in the expectation semiring.\n",
    "\n",
    "Why does `aa_star` in this example have expected reward in the range $(-1,1)$?\n",
    "\n",
    "**Answer**: <span style='color:red'>FILL IN</span>\n",
    "\n",
    "Why does `aa_top` in this example have expected reward of exactly 0?\n",
    "\n",
    "**Answer**: <span style='color:red'>FILL IN</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "9e62912f-a156-40f3-9fed-b46a8f7e6667",
    "deletable": false
   },
   "source": [
    "In fact, there are no paths with strictly positive expected reward, so our Bayes rule should just pick `'OOOOO'`, like Viterbi:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "ab8d6f49-5a10-4f1c-96d7-4ff8818b74ba",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Look for good plans `aa` according to `fsa_reward`\n",
    "for aa in task.iterate_aa(xx=xx):\n",
    "    if expected_reward(aa) >= 0:\n",
    "        expected_reward(aa, trace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "512f3f2d-eab3-4fd4-8281-4a6d6bf74a18",
    "deletable": false
   },
   "source": [
    "But what if we changed the false positive penalty $\\lambda$ to 0?  Then *all* paths except for `'OOOOO'` would surely have positive expected reward (since they posit one or more chunks which have *some* chance of being correct, and *no* penalty for being wrong).  So there must be some intermediate values of $\\lambda$ that also have paths of positive expected reward.  With such a $\\lambda$, our Bayes rule would pick something other than `'OOOOO'`.  We'll be trying this below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "39e740c6-cdff-4f6b-a41e-456ca39f4f03",
    "deletable": false
   },
   "source": [
    "#### Determinization\n",
    "\n",
    "At any rate, we have one more step.  Above we used a brute-force loop to look for good plans `aa`.  But we would like to do that by dynamic programming.\n",
    "\n",
    "We want the `aa` with *maximum* expected reward according to `fsa_reward`.  The problem is that this reward is partitioned over paths.  (Remember that `fsa_reward` was obtained by stripping `yy` labels from `fst_both`.  Some paths accepting `aa` in `fst_reward` have positive reward and some have negative reward, depending on the original `yy` labels.)\n",
    "\n",
    "To consolidate all weights for each `aa` path, we can *determinize* the `fsa_reward` machine, which takes weights in the expectation semring.  Like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "c51e0dd4-08c8-43ca-8dd2-1c92ff715560",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "fsa_reward_det = fsa_reward.determinize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "0b20fa67-96be-477d-b495-d1373dff0bc0",
    "deletable": false
   },
   "source": [
    "The weight of each `aa` is exactly the same as we reported before.  In particular, the total weight of each path has the form $\\langle Z, Z\\bar{r} \\rangle$ where $\\bar{r}$ is the expected reward of `aa`.  Now we just have to find the plan of maximum expected reward.  We can do this by lowering `fsa_reward_det` back into the $(\\max,+)$ semiring and finding the shortest path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "da2d2381-5d43-4487-8ee7-1d11a7dde73a",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "fsa_reward_maxplus = fsa_reward_det \\\n",
    "                     .lift(MaxPlusSemiringWeight, lambda w: w.expectation())\n",
    "\n",
    "\n",
    "# check that aa_star is now accepted along exactly one path that gives its expected value\n",
    "list(fsa_reward_maxplus.compose(FST(''.join(aa_star))).iterate_paths())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "f4c67c37-d5d5-43e2-b774-4dcc7365d5a8",
    "deletable": false
   },
   "source": [
    "Restricting to the legal paths `fsa_aa`, we can find the best legal path (which OpenFST calls the \"shortest\" path), giving the optimal action.  As we knew, the solution is rather boring in this case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "7a4e2422-208f-40f2-b080-49bf498f5ab9",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "fsa_reward_maxplus.compose(task.fsa_aa(xx=xx)).shortest_path()    # restrict to just the legal plans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "cc71f6d5-1fa9-49af-ad81-897a986f3650",
    "deletable": false
   },
   "source": [
    "This construction is manifestly correct, but there is a fly in the ointment.  Unfortunately, determinization blew up the machine exponentially!  If you look at `fsa_reward_det` or `fsa_reward_maxplus`, you'll see that it is a *trie* with a different path for every legal `aa` (and some illegal ones):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "b5798471-cfcf-4012-9f28-680a0c5ca3cc",
    "scrolled": true,
    "deletable": false
   },
   "outputs": [],
   "source": [
    "print(fsa_reward_maxplus.num_states)\n",
    "fsa_reward_maxplus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "524b6ded-bde0-418b-a144-119cbe0c2f96",
    "deletable": false
   },
   "source": [
    "So searching for the best path in this machine is just as bad as the brute-force search over all `aa` values.\n",
    "This would seem to dash our hopes of automatically finding the hand-crafted $O(J^2)$ algorithm.  That algorithm does correspond nicely to the *minimized* version of the DFA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "f6501f53-35b7-49cb-9175-137cd5c4a9e3",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "fsa_reward_maxplus.compose(task.fsa_aa(xx=xx)).minimize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "3f65bd2d-faa6-4481-ba2b-044caf24bc9d",
    "deletable": false
   },
   "source": [
    "You will notice that at time $j$, there are $j+1$ possible states, corresponding to the possible lengths $0, 1, \\ldots, j$ of the longest `BI*` sequence ending at word $j$.  Thus, after reading a prefix of `aa`, the current state keeps track of which chunk (if any) `aa` has begun to propose.  This is necessary to determine how much expected reward might be achieved by future actions that would end the chunk in one place or another.  As for completed chunks before the currently proposed chunk, their expected reward was already accounted for on the path that read the prefix of `aa` (with different paths to the current state corresponding to different prefixes of different rewards).\n",
    "\n",
    "In short, we would quite like to get the $O(J^2)$ machine above and run shortest-path on it, which would be an $O(J^2)$ algorithm.  The difficulty is to get it without first constructing an exponentially large DFA via determinization.  \n",
    "\n",
    "In other words, if two states created by determinization would later be merged by minimization, we would like determinization to regard them as the same state in the first place.  It turns out that this can be done using a trick for \"determinizing better\" in the expectation semiring:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "d18c47cb-9da2-4f1f-94fe-5094d3f48bca",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def determinize_with_merging(self, *args, **kwargs):\n",
    "    assert self.semiring is ExpectationSemiringWeight\n",
    "    ExpectationSemiringWeight.aggressive_quantization = True     # temporarily modifies behavior of `quantize` on expectation semirings (WARNING: not thread-safe)\n",
    "    result = self.push().determinize(*args, **kwargs)            # must push first for aggressive quantization to be correct\n",
    "    ExpectationSemiringWeight.aggressive_quantization = False    \n",
    "    return result\n",
    "\n",
    "FST.determinize_with_merging = determinize_with_merging  # install method dynamically\n",
    "\n",
    "# fsa_reward_det = fsa_reward.compose(task.fsa_aa(xx=xx)).determinize_with_merging()\n",
    "fsa_reward_det = fsa_reward.compose(task.fsa_aa(xx=xx)).determinize_with_merging()\n",
    "fsa_reward_det"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "15dc3029-3dca-4642-a2dd-f3dd9e214c89",
    "deletable": false
   },
   "source": [
    "The topology is identical to the previous minimized machine (except that it continues the pattern even at the final time step $j=5$ of having $j+1$ states, whereas minimization would notice that those states could actually be merged now that the string has ended).  We would complete the construction by again lowering this determinized FSA into the $(\\max,+)$ semiring and finding the highest-weight path.\n",
    "\n",
    "The explanation of the trick is a bit beyond the scope of this homework, but here is a quick sketch.  Determinization is a greedy algorithm that keeps adding states to the determinized machine.  When it creates a  creates a new edge to a state, it looks up a description of the target state in a hash table to determine whether that state has already been created and can be reused.  Reusing existing states is crucial to keeping the machine small: otherwise determinization would *always* create a trie (possibly an infinite one)!  \n",
    "\n",
    "In the weighted case, the state description includes some \"residual weights\" that are elements of the weight semiring.  To allow hash lookup to succeed even if the residual weights are slightly different (e.g., due to floating-point error), OpenFST quantizes the weights before putting them into the state description.  For very interesting reasons, it turns out that in our Bayes agent construction (where the rewards do not affect the arc probabilities), it is safe to quantize the *second* element of the `ExpectationSemiringWeight` by simply making it `0`, provided that weight pushing is applied to the machine before determinization.  This allows states to merge during determinization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "31370733-608e-4f26-92a0-947450880d7f",
    "deletable": false
   },
   "source": [
    "### Putting it all together\n",
    "\n",
    "You now know how to write the following agent!  Just generalize the example above.  Your solution should work whenever `model` is an `FstBoltzmannMachine` and `task` is an `FstTaskSetting`.  It will derive a Bayes decision rule that uses dynamic programming to the extent that is possible given the specific structure of the model and the reward function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "d8ec69a5-1759-4fe7-a8e1-ce59774e8aaa",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "class FstBayesAgent(BayesAgent):\n",
    "    \n",
    "    def decision(self, *, xx, oo=None):\n",
    "        # Hint: Just copy and adjust the commands above.  Make sure to use `self.model` and\n",
    "        #       `self.task`, not the global variables `model` and `task`.  Also make sure\n",
    "        #       to consider `oo`.  \n",
    "        #       For generality, you should call `remove_epsilon()` before determinizing, \n",
    "        #       in case there are any epsilons in the way (perhaps none for this task and model).\n",
    "        ### STUDENTS START\n",
    "        raise NotImplementedError()  # REPLACE ME\n",
    "        ### STUDENTS END\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "b2a5c89f-b078-4766-a9a6-6fca532ff1b1",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def test_bayes_agent(false_pos_penalty):\n",
    "    task = IobTask(false_pos_penalty=false_pos_penalty)   # will have its own reward machine with different weights\n",
    "    agent = FstBayesAgent(task, model)\n",
    "    agent.test_F1(iterate_data('dev'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "6038830f-a336-4428-9e6d-6130679b8c68",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "%time test_bayes_agent(1)   #  what we've been using so far (strongly discourages false positives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "6b68b879-20e7-4552-871e-63e6a749b2a8",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "%time test_bayes_agent(0)    # doesn't mind false positives at all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "cdeca7f8-99c6-416b-866d-2fe6fb5fbdf6",
    "deletable": false
   },
   "source": [
    "Well, that was interesting.  Seems like we'd better try some in-between values of $\\lambda$!  But first, let's pick an in-between value and confirm that our FST agent is doing the same thing as the brute force agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "ade53186-e913-49b5-8fc7-589b27437958",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def compare_agents(false_pos_penalty):\n",
    "    task = IobTask(false_pos_penalty=false_pos_penalty)\n",
    "    agent_old = BayesAgent(task, model)\n",
    "    agent_new = FstBayesAgent(task, model)\n",
    "    for xx,oo,yy in iterate_data('dev-small'):\n",
    "        aa_old = agent_old.decision(xx=xx,oo=oo)\n",
    "        aa_new = agent_new.decision(xx=xx,oo=oo)\n",
    "        assert aa_old==aa_new, f'xx={xx},oo={oo},old={aa_old},new={aa_new}'\n",
    "compare_agents(0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "5eeb2b38-8a75-4057-b44e-b9fcfc81c695",
    "deletable": false
   },
   "source": [
    "If that worked, look for a value of $\\lambda \\geq 0$ that gets high F1 on dev data.  (Remember that $\\lambda$ is tuning a proxy reward to balance precision and recall.)  I suggest trying golden section search, which is a charming little algorithm \u2014 it's quick to implement yourself, or grab some code from the web as long as you understand it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "c996d82e-ce41-4889-bac8-0470c5b5eed6",
    "deletable": false
   },
   "source": [
    "# Studying and developing your system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "deaf965c-2b7f-4eac-afaf-ecb5c9eb1c3e",
    "deletable": false
   },
   "source": [
    "Use the notebook to study what your system is doing.  What are the large parameters in your model?  Do they correspond to frequent words, or other indicators of named entities?  What kinds of errors are you making on training and development data?  If you wanted to add new feature templates, what might they be?  Consider playing with other chunking tasks \u2014 real or artificial \u2014 to get a sense of how your model behaves.\n",
    "\n",
    "Can you improve performance on development data by changing the model, how you train the model, or how you decode?\n",
    "\n",
    "There is a bunch of Python overhead in this implementation.  Discuss specific ways in which the system might be sped up, whether in Python or Cython or by switching to Java or C++.\n",
    "\n",
    "Place your experiments and notes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "0e9362b6-0796-41b0-928a-6258d43b65d2",
    "deletable": false
   },
   "source": [
    "<b>Answer:</b> <span style='color:red'>FILL IN</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "d129c848-ff64-4d5c-a7c3-a34f3969f2bf",
    "deletable": false
   },
   "source": [
    "# The Final Test!!!\n",
    "\n",
    "Now select a particular decision agent for chunking.  It should use a particular model trained in a particular way on the training set, with hyperparameters perhaps informed by your experience on the dev set.  Measure its F1 reward on the **test** dataset, which you have not looked at until now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "c5a851b9-c43d-4859-8270-7728ef81ed18",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "### final_agent = ????\n",
    "### STUDENTS START\n",
    "raise NotImplementedError()  # REPLACE ME\n",
    "### STUDENTS END\n",
    "\n",
    "final_agent.test_F1(iterate_data('test'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}